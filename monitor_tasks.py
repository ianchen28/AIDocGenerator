#!/usr/bin/env python3
"""
ä»»åŠ¡ç›‘æ§è„šæœ¬
ç”¨äºå®æ—¶ç›‘æ§æ–‡æ¡£ç”Ÿæˆä»»åŠ¡çš„æ‰§è¡ŒçŠ¶æ€
"""

import asyncio
import json
import redis.asyncio as redis
import time
from datetime import datetime
from loguru import logger

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(
    sink=lambda msg: print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}"),
    format="{message}",
    level="INFO")


class TaskMonitor:

    def __init__(self, redis_url: str):
        self.redis_url = redis_url
        self.redis_client = None

    async def connect(self):
        """è¿æ¥Redis"""
        try:
            self.redis_client = redis.from_url(self.redis_url,
                                               encoding="utf-8",
                                               decode_responses=True)
            await self.redis_client.ping()
            logger.info("âœ… Redisè¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ Redisè¿æ¥å¤±è´¥: {e}")
            raise

    async def monitor_task_stream(self, task_id: str, duration: int = 300):
        """
        ç›‘æ§æŒ‡å®šä»»åŠ¡çš„Redisæµ
        
        Args:
            task_id: ä»»åŠ¡ID
            duration: ç›‘æ§æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        """
        logger.info(f"ğŸ” å¼€å§‹ç›‘æ§ä»»åŠ¡: {task_id}")
        logger.info(f"â±ï¸ ç›‘æ§æŒç»­æ—¶é—´: {duration}ç§’")

        start_time = time.time()
        last_event_id = "0"

        while time.time() - start_time < duration:
            try:
                # è·å–æ–°äº‹ä»¶
                events = await self.redis_client.xread(
                    {task_id: last_event_id},
                    count=10,
                    block=1000  # ç­‰å¾…1ç§’
                )

                if events:
                    for stream_name, stream_events in events:
                        for event_id, event_data in stream_events:
                            if event_id != last_event_id:
                                await self._process_event(event_id, event_data)
                                last_event_id = event_id

                # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ
                if await self._is_task_completed(task_id):
                    logger.info(f"âœ… ä»»åŠ¡ {task_id} å·²å®Œæˆ")
                    break

            except Exception as e:
                logger.error(f"âŒ ç›‘æ§è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                await asyncio.sleep(1)

        logger.info(f"ğŸ ç›‘æ§ç»“æŸ: {task_id}")

    async def _process_event(self, event_id: str, event_data: dict):
        """å¤„ç†å•ä¸ªäº‹ä»¶"""
        try:
            data_str = event_data.get("data", "{}")
            data = json.loads(data_str)

            event_type = data.get("eventType", "unknown")
            timestamp = data.get("timestamp", "")

            # æ ¹æ®äº‹ä»¶ç±»å‹è¾“å‡ºä¸åŒçš„ä¿¡æ¯
            if event_type == "task_started":
                logger.info(f"ğŸš€ ä»»åŠ¡å¼€å§‹ - {data.get('outline_title', 'æœªçŸ¥æ ‡é¢˜')}")

            elif event_type == "task_progress":
                progress = data.get("progress", "")
                step = data.get("step", "")
                logger.info(f"ğŸ“Š è¿›åº¦æ›´æ–° - {step}: {progress}")

            elif event_type == "chapter_started":
                chapter_title = data.get("chapterTitle", "")
                chapter_index = data.get("chapterIndex", 0)
                total_chapters = data.get("totalChapters", 0)
                logger.info(
                    f"ğŸ“ ç« èŠ‚å¼€å§‹ - {chapter_index + 1}/{total_chapters}: {chapter_title}"
                )

            elif event_type == "chapter_progress":
                chapter_title = data.get("chapterTitle", "")
                step = data.get("step", "")
                progress = data.get("progress", "")
                logger.info(f"âš™ï¸ ç« èŠ‚è¿›åº¦ - {chapter_title} - {step}: {progress}")

            elif event_type == "chapter_completed":
                chapter_title = data.get("chapterTitle", "")
                logger.info(f"âœ… ç« èŠ‚å®Œæˆ - {chapter_title}")

            elif event_type == "writer_started":
                progress = data.get("progress", "")
                logger.info(f"âœï¸ å†™ä½œå¼€å§‹ - {progress}")

            elif event_type == "document_content_stream":
                content = data.get("content", "")
                progress = data.get("progress", "")
                logger.info(f"ğŸ“¤ å†…å®¹æµ - {progress}: {content[:50]}...")

            elif event_type == "citations_completed":
                total_origins = data.get("totalAnswerOrigins", 0)
                total_webs = data.get("totalWebSources", 0)
                logger.info(
                    f"ğŸ“š å‚è€ƒæ–‡çŒ®å®Œæˆ - {total_origins}ä¸ªæ–‡æ¡£æº, {total_webs}ä¸ªç½‘é¡µæº")

            elif event_type == "document_generated":
                document = data.get("document", {})
                title = document.get("title", "")
                word_count = document.get("word_count", 0)
                char_count = document.get("char_count", 0)
                logger.info(
                    f"ğŸ“„ æ–‡æ¡£ç”Ÿæˆ - {title} ({word_count}å­—, {char_count}å­—ç¬¦)")

            elif event_type == "task_completed":
                logger.info(f"ğŸ‰ ä»»åŠ¡å®Œæˆ!")

            elif event_type == "task_failed":
                error = data.get("error", "")
                logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {error}")

            elif event_type == "chapter_failed":
                chapter_title = data.get("chapterTitle", "")
                error = data.get("error", "")
                logger.error(f"âŒ ç« èŠ‚å¤±è´¥ - {chapter_title}: {error}")

            else:
                logger.debug(f"ğŸ” æœªçŸ¥äº‹ä»¶ç±»å‹: {event_type}")

        except Exception as e:
            logger.error(f"âŒ å¤„ç†äº‹ä»¶å¤±è´¥: {e}")

    async def _is_task_completed(self, task_id: str) -> bool:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²å®Œæˆ"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæˆæˆ–å¤±è´¥äº‹ä»¶
            events = await self.redis_client.xrevrange(task_id, count=5)
            for event_id, event_data in events:
                data_str = event_data.get("data", "{}")
                data = json.loads(data_str)
                event_type = data.get("eventType", "")
                if event_type in ["task_completed", "task_failed"]:
                    return True
            return False
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
            return False

    async def list_recent_tasks(self, limit: int = 10):
        """åˆ—å‡ºæœ€è¿‘çš„ä»»åŠ¡"""
        logger.info(f"ğŸ“‹ åˆ—å‡ºæœ€è¿‘ {limit} ä¸ªä»»åŠ¡:")

        try:
            # è·å–æ‰€æœ‰æµ
            keys = await self.redis_client.keys("*")
            task_streams = [
                key for key in keys if key.isdigit() and len(key) > 10
            ]

            task_info = []
            for task_id in task_streams[-limit:]:
                try:
                    # è·å–ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªäº‹ä»¶
                    first_event = await self.redis_client.xrange(task_id,
                                                                 count=1)
                    last_event = await self.redis_client.xrevrange(task_id,
                                                                   count=1)

                    if first_event and last_event:
                        first_data = json.loads(first_event[0][1].get(
                            "data", "{}"))
                        last_data = json.loads(last_event[0][1].get(
                            "data", "{}"))

                        task_info.append({
                            "task_id":
                            task_id,
                            "title":
                            first_data.get("outline_title", "æœªçŸ¥"),
                            "start_time":
                            first_data.get("timestamp", ""),
                            "last_event":
                            last_data.get("eventType", ""),
                            "status":
                            "running" if last_data.get("eventType") not in [
                                "task_completed", "task_failed"
                            ] else "completed"
                        })
                except Exception as e:
                    logger.error(f"âŒ è·å–ä»»åŠ¡ {task_id} ä¿¡æ¯å¤±è´¥: {e}")

            # æŒ‰æ—¶é—´æ’åº
            task_info.sort(key=lambda x: x["start_time"], reverse=True)

            for task in task_info:
                status_emoji = "ğŸŸ¢" if task["status"] == "completed" else "ğŸŸ¡"
                logger.info(
                    f"{status_emoji} {task['task_id']} - {task['title']} ({task['status']})"
                )

        except Exception as e:
            logger.error(f"âŒ åˆ—å‡ºä»»åŠ¡å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    # Redisé…ç½®
    redis_url = "redis://:xJrhp*4mnHxbBWN2grqq@10.215.149.74:26379/0"

    monitor = TaskMonitor(redis_url)
    await monitor.connect()

    # åˆ—å‡ºæœ€è¿‘çš„ä»»åŠ¡
    await monitor.list_recent_tasks()

    # å¦‚æœæœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œç›‘æ§æŒ‡å®šä»»åŠ¡
    import sys
    if len(sys.argv) > 1:
        task_id = sys.argv[1]
        await monitor.monitor_task_stream(task_id)
    else:
        logger.info("ğŸ’¡ ä½¿ç”¨æ–¹æ³•: python monitor_tasks.py <task_id>")
        logger.info("ğŸ’¡ ä¾‹å¦‚: python monitor_tasks.py 1754566940616110086")


if __name__ == "__main__":
    asyncio.run(main())
