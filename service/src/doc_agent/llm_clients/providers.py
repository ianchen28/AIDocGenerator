# service/src/doc_agent/llm_clients/providers.py
from loguru import logger
import pprint
import re
import httpx
from .base import LLMClient
from .base import BaseOutputParser


class ReasoningParser(BaseOutputParser):
    """
    æ¨ç†è¾“å‡ºè§£æå™¨
    å»é™¤æ¨¡å‹å“åº”ä¸­çš„æ¨ç†è¿‡ç¨‹ï¼Œåªä¿ç•™æœ€ç»ˆç­”æ¡ˆ
    """

    def __init__(self, reasoning: bool = False):
        self.reasoning = reasoning

    def parse(self, response: str) -> str:
        if self.reasoning:
            # ç”¨æ­£åˆ™è¡¨è¾¾å¼å»é™¤ <think> å’Œ </think> ä¹‹é—´çš„å†…å®¹
            response = re.sub(r'<think>.*?</think>',
                              '',
                              response,
                              flags=re.DOTALL)
            return response.strip()
        else:
            return response.strip()


class GeminiClient(LLMClient):

    def __init__(self,
                 base_url: str,
                 model_name: str = "gemini-1.5-pro-latest",
                 api_key: str = None,
                 reasoning: bool = False):
        """
        åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯
        
        Args:
            api_key: Gemini APIå¯†é’¥
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸ºgemini-1.5-pro-latest
            base_url: APIåŸºç¡€URLï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤URL
        """
        self.api_key = api_key
        self.model_name = model_name
        self.reasoning = reasoning
        self.parser = ReasoningParser(reasoning=reasoning)
        # å¦‚æœæä¾›äº†base_urlï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤URL
        if base_url:
            self.base_url = base_url.rstrip('/')
        else:
            self.base_url = "https://generativelanguage.googleapis.com/v1beta/models"

    def invoke(self, prompt: str, **kwargs) -> str:
        """
        è°ƒç”¨Gemini API
        
        Args:
            prompt: è¾“å…¥æç¤º
            **kwargs: å…¶ä»–å‚æ•°ï¼Œå¦‚temperature, max_tokensç­‰
            
        Returns:
            str: æ¨¡å‹å“åº”çš„å†…å®¹
        """
        try:
            # è·å–å¯é€‰å‚æ•°
            temperature = kwargs.get("temperature", 0.7)
            max_tokens = kwargs.get("max_tokens", 1000)

            # æ„å»ºè¯·æ±‚æ•°æ®
            data = {
                "contents": [{
                    "parts": [{
                        "text": prompt
                    }]
                }],
                "generationConfig": {
                    "temperature": temperature,
                    "maxOutputTokens": max_tokens
                }
            }

            # å‘é€è¯·æ±‚ - ä¿®å¤ Gemini API URL
            # ChatAI API ä½¿ç”¨ä¸åŒçš„ç«¯ç‚¹æ ¼å¼
            if "chataiapi.com" in self.base_url:
                # ChatAI API æ ¼å¼
                url = f"{self.base_url}/chat/completions"
                headers = {"Authorization": f"Bearer {self.api_key}"}
                # ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼
                data = {
                    "model": self.model_name,
                    "messages": [{
                        "role": "user",
                        "content": prompt
                    }],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                }
            else:
                # æ ‡å‡† Gemini API æ ¼å¼
                url = f"{self.base_url}/{self.model_name}:generateContent?key={self.api_key}"
                headers = {}
                # ä½¿ç”¨ Gemini æ ¼å¼
                data = {
                    "contents": [{
                        "parts": [{
                            "text": prompt
                        }]
                    }],
                    "generationConfig": {
                        "temperature": temperature,
                        "maxOutputTokens": max_tokens
                    }
                }

            logger.debug(
                f"Gemini API request:\nURL: {url}\nData: {pprint.pformat(data)}"
            )

            with httpx.Client(timeout=60.0) as client:
                response = client.post(url, json=data, headers=headers)
                response.raise_for_status()

                result = response.json()

                # æå–å“åº”å†…å®¹ - æ”¯æŒä¸¤ç§æ ¼å¼
                if "chataiapi.com" in self.base_url:
                    # ChatAI API è¿”å› OpenAI å…¼å®¹æ ¼å¼
                    if "choices" in result and len(result["choices"]) > 0:
                        content = result["choices"][0]["message"]["content"]
                        logger.debug(f"ğŸ” ChatAIåŸå§‹å“åº”: '{content}'")
                        parsed_content = self.parser.parse(content)
                        logger.debug(f"ğŸ” ChatAIè§£æå: '{parsed_content}'")
                        return parsed_content
                    else:
                        raise ValueError(
                            "No response content received from ChatAI API")
                else:
                    # æ ‡å‡† Gemini API æ ¼å¼
                    if "candidates" in result and len(
                            result["candidates"]) > 0:
                        content = result["candidates"][0]["content"]["parts"][
                            0]["text"]
                        logger.debug(f"ğŸ” GeminiåŸå§‹å“åº”: '{content}'")
                        parsed_content = self.parser.parse(content)
                        logger.debug(f"ğŸ” Geminiè§£æå: '{parsed_content}'")
                        return parsed_content
                    else:
                        raise ValueError(
                            "No response content received from Gemini API")

        except Exception as e:
            logger.error(f"Gemini APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise Exception(f"Gemini APIè°ƒç”¨å¤±è´¥: {str(e)}")


class DeepSeekClient(LLMClient):

    def __init__(self,
                 base_url: str,
                 api_key: str,
                 model_name: str,
                 reasoning: bool = False):
        """
        åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯
        
        Args:
            api_key: DeepSeek APIå¯†é’¥
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸ºdeepseek-chat
        """
        self.api_key = api_key
        self.model_name = model_name
        self.reasoning = reasoning
        self.parser = ReasoningParser(reasoning=reasoning)
        self.base_url = base_url.rstrip('/')

    def invoke(self, prompt: str, **kwargs) -> str:
        """
        è°ƒç”¨DeepSeek API
        
        Args:
            prompt: è¾“å…¥æç¤º
            **kwargs: å…¶ä»–å‚æ•°ï¼Œå¦‚temperature, max_tokensç­‰
            
        Returns:
            str: æ¨¡å‹å“åº”çš„å†…å®¹
        """
        try:
            # è·å–å¯é€‰å‚æ•°
            temperature = kwargs.get("temperature", 0.7)
            max_tokens = kwargs.get("max_tokens", 1000)

            # æ„å»ºè¯·æ±‚æ•°æ®
            data = {
                "model": self.model_name,
                "messages": [{
                    "role": "user",
                    "content": prompt
                }],
                "temperature": temperature,
                "max_tokens": max_tokens
            }

            logger.debug(
                f"DeepSeek API request:\nURL: {self.base_url}/chat/completions\nData: {pprint.pformat(data)}"
            )

            # å‘é€è¯·æ±‚
            url = f"{self.base_url}/chat/completions"
            headers = {"Authorization": f"Bearer {self.api_key}"}

            with httpx.Client(timeout=60.0) as client:
                response = client.post(url, json=data, headers=headers)
                response.raise_for_status()

                result = response.json()

                # æå–å“åº”å†…å®¹
                if "choices" in result and len(result["choices"]) > 0:
                    content = result["choices"][0]["message"]["content"]
                    return self.parser.parse(content)
                else:
                    raise ValueError(
                        "No response content received from DeepSeek API")

        except Exception as e:
            logger.error(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise Exception(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {str(e)}")


class MoonshotClient(LLMClient):

    def __init__(self,
                 base_url: str,
                 api_key: str,
                 model_name: str,
                 reasoning: bool = False):
        """
        åˆå§‹åŒ–Moonshotå®¢æˆ·ç«¯
        
        Args:
            base_url: Moonshot APIåœ°å€
            api_key: APIå¯†é’¥
            model: æ¨¡å‹åç§°
        """
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key
        self.model_name = model_name
        self.reasoning = reasoning
        self.parser = ReasoningParser(reasoning=reasoning)

    def invoke(self, prompt: str, **kwargs) -> str:
        """
        è°ƒç”¨Moonshot API
        
        Args:
            prompt: è¾“å…¥æç¤º
            **kwargs: å…¶ä»–å‚æ•°ï¼Œå¦‚temperature, max_tokensç­‰
            
        Returns:
            str: æ¨¡å‹å“åº”çš„å†…å®¹
        """
        try:
            # è·å–å¯é€‰å‚æ•°
            temperature = kwargs.get("temperature", 0.7)
            max_tokens = kwargs.get("max_tokens", 1000)

            # æ„å»ºè¯·æ±‚æ•°æ® - ä½¿ç”¨OpenAIå…¼å®¹æ ¼å¼
            data = {
                "model": self.model_name,
                "messages": [{
                    "role": "user",
                    "content": prompt
                }],
                "temperature": temperature,
                "max_tokens": max_tokens
            }

            logger.debug(
                f"Moonshot API request:\nURL: {self.base_url}/chat/completions\nData: {pprint.pformat(data)}"
            )

            # å‘é€è¯·æ±‚
            url = f"{self.base_url}/chat/completions"
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }

            # åˆ›å»ºè‡ªå®šä¹‰çš„httpxå®¢æˆ·ç«¯ï¼Œé¿å…proxieså‚æ•°é—®é¢˜
            http_client = httpx.Client(timeout=60.0)

            with http_client as client:
                response = client.post(url, json=data, headers=headers)
                response.raise_for_status()

                result = response.json()

                # æå–å“åº”å†…å®¹
                if "choices" in result and len(result["choices"]) > 0:
                    content = result["choices"][0]["message"]["content"]
                    logger.debug(f"ğŸ” MoonshotåŸå§‹å“åº”: '{content}'")
                    parsed_content = self.parser.parse(content)
                    logger.debug(f"ğŸ” Moonshotè§£æå: '{parsed_content}'")
                    return parsed_content
                else:
                    raise ValueError(
                        "No response content received from Moonshot API")

        except Exception as e:
            logger.error(f"Moonshot APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise Exception(f"Moonshot APIè°ƒç”¨å¤±è´¥: {str(e)}")


class InternalLLMClient(LLMClient):

    def __init__(self,
                 base_url: str,
                 api_key: str,
                 model_name: str,
                 reasoning: bool = False):
        """
        åˆå§‹åŒ–å†…éƒ¨æ¨¡å‹å®¢æˆ·ç«¯
        
        Args:
            base_url: å†…éƒ¨APIåœ°å€
            api_key: APIå¯†é’¥
            model: æ¨¡å‹åç§°
        """
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key
        self.model_name = model_name
        self.reasoning = reasoning
        self.parser = ReasoningParser(reasoning=reasoning)

    def invoke(self, prompt: str, **kwargs) -> str:
        """
        è°ƒç”¨å†…éƒ¨æ¨¡å‹API
        
        Args:
            prompt: è¾“å…¥æç¤º
            **kwargs: å…¶ä»–å‚æ•°ï¼Œå¦‚temperature, max_tokensç­‰
            
        Returns:
            str: æ¨¡å‹å“åº”çš„å†…å®¹
        """
        try:
            # è·å–å¯é€‰å‚æ•°
            temperature = kwargs.get("temperature", 0.7)
            max_tokens = kwargs.get("max_tokens", 1000)

            # æ„å»ºè¯·æ±‚æ•°æ®
            data = {
                "model": self.model_name,
                "messages": [{
                    "role": "user",
                    "content": prompt
                }],
                "temperature": temperature,
                "max_tokens": max_tokens
            }

            logger.debug(
                f"Internal API request:\nURL: {self.base_url}/chat/completions\nData: {pprint.pformat(data)}"
            )

            # å‘é€è¯·æ±‚
            url = f"{self.base_url}/chat/completions"
            headers = {
                "Authorization": f"Bearer {self.api_key}"
            } if self.api_key != "EMPTY" else {}

            with httpx.Client(timeout=180.0) as client:  # å†…éƒ¨æ¨¡å‹å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
                response = client.post(url, json=data, headers=headers)
                response.raise_for_status()

                result = response.json()

                # æå–å“åº”å†…å®¹
                if "choices" in result and len(result["choices"]) > 0:
                    content = result["choices"][0]["message"]["content"]
                    return self.parser.parse(content)
                else:
                    raise ValueError(
                        "No response content received from Internal API")

        except Exception as e:
            logger.error(f"Internal APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise Exception(f"Internal APIè°ƒç”¨å¤±è´¥: {str(e)}")


class RerankerClient(LLMClient):

    def __init__(self, base_url: str, api_key: str):
        """
        åˆå§‹åŒ–Rerankerå®¢æˆ·ç«¯
        
        Args:
            base_url: Reranker APIåœ°å€
            api_key: APIå¯†é’¥
        """
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key

    def invoke(self, prompt: str, **kwargs) -> dict:
        """
        è°ƒç”¨Reranker API
        Args:
            prompt: è¾“å…¥æç¤º
            **kwargs: å…¶ä»–å‚æ•°
        Returns:
            dict: é‡æ’åºç»“æœ
        """
        try:
            documents = kwargs.get("documents", [])
            doc_objs = [{"text": doc} for doc in documents]
            size = kwargs.get("size", len(doc_objs))
            data = {"query": prompt, "doc_list": doc_objs, "size": size}
            url = f"{self.base_url}"
            headers = {
                "Authorization": f"Bearer {self.api_key}"
            } if self.api_key != "EMPTY" else {}

            logger.debug(
                f"Reranker API request:\nURL: {url}\nData: {pprint.pformat(data)}"
            )

            with httpx.Client(timeout=60.0) as client:
                response = client.post(url, json=data, headers=headers)
                response.raise_for_status()
                result = response.json()
                return result
        except Exception as e:
            logger.error(f"Reranker APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise Exception(f"Reranker APIè°ƒç”¨å¤±è´¥: {str(e)}")


class EmbeddingClient(LLMClient):

    def __init__(self, base_url: str, api_key: str):
        """
        åˆå§‹åŒ–Embeddingå®¢æˆ·ç«¯
        
        Args:
            base_url: Embedding APIåœ°å€
            api_key: APIå¯†é’¥
        """
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key

    def invoke(self, prompt: str, **kwargs) -> str:
        """
        è°ƒç”¨Embedding API
        Args:
            prompt: è¾“å…¥æ–‡æœ¬
            **kwargs: å…¶ä»–å‚æ•°
        Returns:
            str: åµŒå…¥å‘é‡ï¼ˆJSONæ ¼å¼ï¼‰
        """
        try:
            # æ„å»ºè¯·æ±‚æ•°æ® - ä¿®å¤å­—æ®µå
            data = {"inputs": prompt, "model": kwargs.get("model", "gte-qwen")}

            logger.debug(
                f"Embedding API request:\nURL: {self.base_url}\nData: {pprint.pformat(data)}"
            )

            # å‘é€è¯·æ±‚ - ç›´æ¥ä½¿ç”¨æ ¹ç«¯ç‚¹ï¼Œå› ä¸ºæµ‹è¯•æ˜¾ç¤ºå®ƒå·¥ä½œæ­£å¸¸
            url = f"{self.base_url}"
            headers = {
                "Authorization": f"Bearer {self.api_key}"
            } if self.api_key != "EMPTY" else {}

            with httpx.Client(timeout=60.0) as client:
                response = client.post(url, json=data, headers=headers)
                response.raise_for_status()
                result = response.json()
                return str(result)  # è¿”å›åµŒå…¥å‘é‡

        except Exception as e:
            logger.error(f"Embedding APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise Exception(f"Embedding APIè°ƒç”¨å¤±è´¥: {str(e)}")
