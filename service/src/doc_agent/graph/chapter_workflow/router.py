# service/src/doc_agent/graph/router.py
import pprint
from typing import Literal

from loguru import logger

from doc_agent.common.prompt_selector import PromptSelector
from doc_agent.graph.state import ResearchState
from doc_agent.llm_clients.base import LLMClient


def supervisor_router(
    state: ResearchState,
    llm_client: LLMClient,
    prompt_selector: PromptSelector,
    genre: str = "default"
) -> Literal["continue_to_writer", "rerun_researcher"]:
    """
    æ¡ä»¶è·¯ç”±: å†³ç­–ä¸‹ä¸€æ­¥èµ°å‘
    è¯„ä¼°æ”¶é›†çš„ç ”ç©¶æ•°æ®æ˜¯å¦è¶³å¤Ÿæ’°å†™é«˜è´¨é‡æ–‡æ¡£
    Args:
        state: ç ”ç©¶çŠ¶æ€ï¼ŒåŒ…å« topic å’Œ gathered_data
        llm_client: LLMå®¢æˆ·ç«¯å®ä¾‹
        prompt_selector: PromptSelectorå®ä¾‹ï¼Œç”¨äºè·å–promptæ¨¡æ¿
        genre: genreç±»å‹ï¼Œé»˜è®¤ä¸º"default"
    Returns:
        str: "continue_to_writer" å¦‚æœæ•°æ®å……è¶³ï¼Œ"rerun_researcher" å¦‚æœéœ€è¦æ›´å¤šç ”ç©¶
    """
    logger.info("ğŸš€ ====== è¿›å…¥ supervisor_router è·¯ç”±èŠ‚ç‚¹ ======")

    # 1. ä»çŠ¶æ€ä¸­æå– topic å’Œç ”ç©¶æ•°æ®
    topic = state.get("topic", "")
    gathered_sources = state.get("gathered_sources", [])
    gathered_data = state.get("gathered_data", "")  # ä¿æŒå‘åå…¼å®¹

    if not topic:
        # å¦‚æœæ²¡æœ‰ä¸»é¢˜ï¼Œé»˜è®¤éœ€è¦é‡æ–°ç ”ç©¶
        logger.warning("âŒ æ²¡æœ‰ä¸»é¢˜ï¼Œè¿”å› rerun_researcher")
        return "rerun_researcher"

    # æ£€æŸ¥æ˜¯å¦æœ‰ç ”ç©¶æ•°æ®ï¼ˆä¼˜å…ˆæ£€æŸ¥ gathered_sourcesï¼‰
    if not gathered_sources and not gathered_data:
        # å¦‚æœæ²¡æœ‰æ”¶é›†åˆ°æ•°æ®ï¼Œéœ€è¦é‡æ–°ç ”ç©¶
        logger.warning("âŒ æ²¡æœ‰æ”¶é›†åˆ°æ•°æ®ï¼Œè¿”å› rerun_researcher")
        return "rerun_researcher"

    # 2. é¢„åˆ†ææ­¥éª¤ï¼šè®¡ç®—å…ƒæ•°æ®
    if gathered_sources:
        # ä½¿ç”¨æ–°çš„ Source å¯¹è±¡æ ¼å¼
        num_sources = len(gathered_sources)
        total_length = sum(len(source.content) for source in gathered_sources)
        logger.info(f"ğŸ“Š ä½¿ç”¨ gathered_sources æ ¼å¼ï¼Œæ¥æºæ•°é‡: {num_sources}")
    else:
        # ä½¿ç”¨æ—§çš„å­—ç¬¦ä¸²æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
        num_sources = gathered_data.count("===")
        total_length = len(gathered_data)
        logger.info(f"ğŸ“Š ä½¿ç”¨ gathered_data æ ¼å¼ï¼Œæ¥æºæ•°é‡: {num_sources}")

    logger.info(f"ğŸ“‹ Topic: {topic}")
    logger.info(f"ğŸ“Š Gathered data é•¿åº¦: {total_length} å­—ç¬¦")
    logger.info(f"ğŸ” æ¥æºæ•°é‡: {num_sources}")

    # ä½¿ç”¨ PromptSelector è·å– prompt æ¨¡æ¿
    try:
        prompt_template = prompt_selector.get_prompt("prompts", "supervisor",
                                                     genre)
        logger.debug(f"âœ… æˆåŠŸè·å– supervisor prompt æ¨¡æ¿ï¼Œgenre: {genre}")
    except Exception as e:
        logger.error(f"âŒ è·å– supervisor prompt æ¨¡æ¿å¤±è´¥: {e}")
        # ä½¿ç”¨é»˜è®¤çš„ prompt æ¨¡æ¿ä½œä¸ºå¤‡ç”¨
        prompt_template = """**è§’è‰²ï¼š** ä½ æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„å†³ç­–æœºå™¨äººã€‚
**ä»»åŠ¡ï¼š** æ ¹æ®ä¸‹æ–¹çš„æ•°æ®æ‘˜è¦ï¼Œåˆ¤æ–­æ˜¯å¦å¯ä»¥å¼€å§‹ä¸ºã€Œ{topic}ã€æ’°å†™ä¸€ä¸ªç« èŠ‚ã€‚

**å†³ç­–æ ‡å‡†ï¼š**
- å¦‚æœæ¥æºæ•°é‡ >= 3 ä¸”æ€»å­—ç¬¦æ•° >= 200ï¼Œè¿”å› "FINISH"
- å¦‚æœæ¥æºæ•°é‡ >= 2 ä¸”æ€»å­—ç¬¦æ•° >= 500ï¼Œè¿”å› "FINISH"
- å…¶ä»–æƒ…å†µè¿”å› "CONTINUE"

**æ•°æ®æ‘˜è¦ï¼š**
- æ¥æºæ•°é‡: {num_sources}
- æ€»å­—ç¬¦æ•°: {total_length}

**ä½ çš„å†³ç­–ï¼š**
ä½ çš„å›ç­”åªèƒ½æ˜¯ä¸€ä¸ªå•è¯ï¼š"FINISH" æˆ– "CONTINUE"ã€‚
"""

    # 3. æ„å»ºç®€åŒ–çš„è¯„ä¼°æç¤ºè¯
    prompt = prompt_template.format(topic=topic,
                                    num_sources=num_sources,
                                    total_length=total_length)

    logger.debug(
        f"Invoking LLM with supervisor prompt:\n{pprint.pformat(prompt)}")

    try:
        # 4. è°ƒç”¨ LLM å®¢æˆ·ç«¯
        # ä½¿ç”¨å°çš„ max_tokensï¼Œå› ä¸ºæœŸæœ›çš„è¾“å‡ºå¾ˆçŸ­
        max_tokens = 10

        logger.info("ğŸ¤– è°ƒç”¨ LLM è¿›è¡Œå†³ç­–åˆ¤æ–­...")
        logger.debug(f"ğŸ“ Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
        logger.debug(f"ğŸ”§ å‚æ•°: max_tokens={max_tokens}, temperature=0")

        # æ·»åŠ é‡è¯•æœºåˆ¶
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = llm_client.invoke(prompt,
                                             temperature=0,
                                             max_tokens=max_tokens)
                break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯
            except Exception as e:
                if "400" in str(e) and attempt < max_retries - 1:
                    logger.warning(
                        f"âš ï¸  ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥ (400é”™è¯¯)ï¼Œæ­£åœ¨é‡è¯•...")
                    import time
                    time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                    continue
                else:
                    raise e  # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥æˆ–å…¶ä»–é”™è¯¯ï¼ŒæŠ›å‡ºå¼‚å¸¸

                # 4. è§£æå“åº” - ç®€åŒ–å¤„ç†é€»è¾‘
        # ç›´æ¥æ£€æŸ¥å“åº”ä¸­æ˜¯å¦åŒ…å« "FINISH" æˆ– "CONTINUE"
        decision = response.strip().upper()
        clean_response = response  # åˆå§‹åŒ– clean_response

        # å¦‚æœå“åº”è¢«æˆªæ–­æˆ–åŒ…å«æ¨ç†è¿‡ç¨‹ï¼Œå°è¯•æå–å†³ç­–å…³é”®è¯
        if "FINISH" not in decision and "CONTINUE" not in decision:
            # å°è¯•ä»å“åº”ä¸­æå–ä»»ä½•å¯èƒ½çš„å†³ç­–è¯
            import re
            # ç§»é™¤å¯èƒ½çš„æ¨ç†æ ‡ç­¾
            clean_response = re.sub(r'<think>.*',
                                    '',
                                    response,
                                    flags=re.IGNORECASE)
            clean_response = re.sub(r'<THINK>.*',
                                    '',
                                    clean_response,
                                    flags=re.IGNORECASE)
            decision = clean_response.strip().upper()

        # æ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
        logger.debug(f"ğŸ” LLMåŸå§‹å“åº”: '{response}'")
        logger.debug(f"ğŸ” å“åº”é•¿åº¦: {len(response)} å­—ç¬¦")
        logger.debug(f"ğŸ” æ¸…ç†åå“åº”: '{clean_response}'")
        logger.debug(f"ğŸ” å¤„ç†åå†³ç­–: '{decision}'")
        logger.debug(f"ğŸ” æ˜¯å¦åŒ…å«FINISH: {'FINISH' in decision}")
        logger.debug(f"ğŸ” æ˜¯å¦åŒ…å«CONTINUE: {'CONTINUE' in decision}")

        # 5. æ ¹æ®å“åº”å†³å®šè·¯ç”±
        if "FINISH" in decision:
            logger.info("âœ… å†³ç­–: FINISH -> continue_to_writer")
            return "continue_to_writer"
        else:
            # å¦‚æœåŒ…å« "CONTINUE" æˆ–å…¶ä»–ä»»ä½•å†…å®¹ï¼Œéƒ½éœ€è¦é‡æ–°ç ”ç©¶
            logger.info("âœ… å†³ç­–: CONTINUE/å…¶ä»– -> rerun_researcher")
            return "rerun_researcher"

    except Exception as e:
        # å¦‚æœ LLM è°ƒç”¨å¤±è´¥ï¼Œé»˜è®¤ç»§ç»­ç ”ç©¶ä»¥ç¡®ä¿å®‰å…¨
        logger.error(f"âŒ Supervisor router error: {str(e)}")
        logger.error(f"âŒ é”™è¯¯ç±»å‹: {type(e).__name__}")
        return "rerun_researcher"
