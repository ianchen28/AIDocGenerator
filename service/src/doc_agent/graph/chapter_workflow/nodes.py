# service/src/doc_agent/graph/nodes.py
from ..state import ResearchState
from ...llm_clients.base import LLMClient
from ...tools.web_search import WebSearchTool
from ...tools.es_search import ESSearchTool
from ...tools.reranker import RerankerTool
from ...llm_clients.providers import EmbeddingClient, RerankerClient

# æ·»åŠ é…ç½®å¯¼å…¥
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_file = Path(__file__)
service_dir = None
for parent in current_file.parents:
    if parent.name == 'service':
        service_dir = parent
        break

if service_dir and str(service_dir) not in sys.path:
    sys.path.insert(0, str(service_dir))

from core.config import settings

# ä¿®å¤ç›¸å¯¹å¯¼å…¥
# ç›´æ¥å¯¼å…¥utilsæ¨¡å—
import sys
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
current_file = Path(__file__)
service_dir = None
for parent in current_file.parents:
    if parent.name == 'service':
        service_dir = parent
        break

if service_dir:
    src_dir = service_dir / "src"
    if str(src_dir) not in sys.path:
        sys.path.insert(0, str(src_dir))

# å¯¼å…¥utilsæ¨¡å—
import sys
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
current_file = Path(__file__)
service_dir = None
for parent in current_file.parents:
    if parent.name == 'service':
        service_dir = parent
        break

if service_dir:
    src_dir = service_dir / "src"
    if str(src_dir) not in sys.path:
        sys.path.insert(0, str(src_dir))

# ç›´æ¥å¯¼å…¥utils.pyæ–‡ä»¶
import sys
import os

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', '..'))
from doc_agent.common import parse_planner_response
from doc_agent.utils.search_utils import search_and_rerank


def planner_node(state: ResearchState, llm_client: LLMClient) -> dict:
    """
    èŠ‚ç‚¹1: è§„åˆ’ç ”ç©¶æ­¥éª¤
    
    ä»çŠ¶æ€ä¸­è·å– topic å’Œå½“å‰ç« èŠ‚ä¿¡æ¯ï¼Œåˆ›å»º prompt è°ƒç”¨ LLM ç”Ÿæˆç ”ç©¶è®¡åˆ’å’Œæœç´¢æŸ¥è¯¢
    
    Args:
        state: ç ”ç©¶çŠ¶æ€ï¼ŒåŒ…å« topic å’Œå½“å‰ç« èŠ‚ä¿¡æ¯
        llm_client: LLMå®¢æˆ·ç«¯å®ä¾‹
        
    Returns:
        dict: åŒ…å« research_plan å’Œ search_queries çš„å­—å…¸
    """
    topic = state.get("topic", "")
    current_chapter_index = state.get("current_chapter_index", 0)
    chapters_to_process = state.get("chapters_to_process", [])

    if not topic:
        raise ValueError("Topic is required in state")

    # è·å–å½“å‰ç« èŠ‚ä¿¡æ¯
    current_chapter = None
    if current_chapter_index < len(chapters_to_process):
        current_chapter = chapters_to_process[current_chapter_index]

    chapter_title = current_chapter.get("chapter_title",
                                        "") if current_chapter else ""
    chapter_description = current_chapter.get("description",
                                              "") if current_chapter else ""

    print(f"ğŸ“‹ è§„åˆ’ç« èŠ‚ç ”ç©¶: {chapter_title}")
    print(f"ğŸ“ ç« èŠ‚æè¿°: {chapter_description}")

    # è·å–ä»»åŠ¡è§„åˆ’å™¨é…ç½®
    task_planner_config = settings.get_agent_component_config("task_planner")
    if not task_planner_config:
        raise ValueError("Task planner configuration not found")

    # åˆ›å»ºç ”ç©¶è®¡åˆ’ç”Ÿæˆçš„ promptï¼Œè¦æ±‚ JSON æ ¼å¼å“åº”
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶è§„åˆ’ä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹ç« èŠ‚åˆ¶å®šè¯¦ç»†çš„ç ”ç©¶è®¡åˆ’å’Œæœç´¢ç­–ç•¥ã€‚

**æ–‡æ¡£ä¸»é¢˜:** {topic}
**å½“å‰ç« èŠ‚:** {chapter_title}
**ç« èŠ‚æè¿°:** {chapter_description}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–å†…å®¹ï¼š

{{
    "research_plan": "è¯¦ç»†çš„ç ”ç©¶è®¡åˆ’ï¼ŒåŒ…æ‹¬ï¼š1. éœ€è¦äº†è§£çš„æ ¸å¿ƒæ¦‚å¿µ 2. éœ€è¦æ”¶é›†çš„ä¿¡æ¯ç±»å‹ 3. ç ”ç©¶çš„æ—¶é—´å®‰æ’ 4. å¯èƒ½é‡åˆ°çš„æŒ‘æˆ˜å’Œè§£å†³æ–¹æ¡ˆ",
    "search_queries": ["å…·ä½“çš„æœç´¢æŸ¥è¯¢1", "å…·ä½“çš„æœç´¢æŸ¥è¯¢2", "å…·ä½“çš„æœç´¢æŸ¥è¯¢3", "å…·ä½“çš„æœç´¢æŸ¥è¯¢4", "å…·ä½“çš„æœç´¢æŸ¥è¯¢5"]
}}

è¦æ±‚ï¼š
1. research_plan åº”è¯¥æ˜¯ä¸€ä¸ªè¯¦ç»†çš„æ­¥éª¤è®¡åˆ’ï¼ŒåŒ…å«å…·ä½“çš„ç ”ç©¶æ­¥éª¤å’Œç­–ç•¥
2. search_queries åº”è¯¥åŒ…å«3-5ä¸ªå…·ä½“çš„æœç´¢æŸ¥è¯¢ï¼Œæ¯ä¸ªæŸ¥è¯¢è¦é’ˆå¯¹æ€§å¼ºä¸”è¦†ç›–ç« èŠ‚çš„ä¸åŒæ–¹é¢
3. å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºï¼Œç¡®ä¿ JSON æ ¼å¼æ­£ç¡®
4. æœç´¢æŸ¥è¯¢åº”è¯¥ä½¿ç”¨é€šç”¨å…³é”®è¯ï¼Œé¿å…è¿‡äºå…·ä½“çš„æœ¯è¯­ï¼Œç¡®ä¿èƒ½åœ¨çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›¸å…³å†…å®¹
5. æœç´¢æŸ¥è¯¢åº”è¯¥åŒ…å«ä¸»é¢˜çš„æ ¸å¿ƒè¯æ±‡ï¼Œæ¯”å¦‚"æ°´ç”µç«™"ã€"ç”µåŠ›"ã€"èƒ½æº"ç­‰é€šç”¨æœ¯è¯­
6. æœç´¢æŸ¥è¯¢åº”è¯¥é’ˆå¯¹å½“å‰ç« èŠ‚çš„å…·ä½“å†…å®¹ï¼Œç»“åˆç« èŠ‚æ ‡é¢˜å’Œæè¿°
"""

    try:
        # è°ƒç”¨ LLM ç”Ÿæˆç ”ç©¶è®¡åˆ’
        response = llm_client.invoke(
            prompt,
            temperature=task_planner_config.temperature,
            max_tokens=task_planner_config.max_tokens,
            **task_planner_config.extra_params)

        print(f"ğŸ” LLMåŸå§‹å“åº”: {repr(response)}")
        print(f"ğŸ“ å“åº”é•¿åº¦: {len(response)} å­—ç¬¦")

        # è§£æ JSON å“åº”
        research_plan, search_queries = parse_planner_response(response)

        print(f"âœ… ç”Ÿæˆç ”ç©¶è®¡åˆ’: {len(search_queries)} ä¸ªæœç´¢æŸ¥è¯¢")
        for i, query in enumerate(search_queries, 1):
            print(f"  {i}. {query}")

        # è¿”å›å®Œæ•´çš„çŠ¶æ€æ›´æ–°
        result = {
            "research_plan": research_plan,
            "search_queries": search_queries
        }
        print(f"ğŸ“¤ PlannerèŠ‚ç‚¹è¿”å›ç»“æœ: {result}")
        return result

    except Exception as e:
        # å¦‚æœ LLM è°ƒç”¨å¤±è´¥ï¼Œè¿”å›é»˜è®¤è®¡åˆ’
        print(f"Planner node error: {str(e)}")
        default_queries = [
            f"{topic} {chapter_title} æ¦‚è¿°", f"{topic} {chapter_title} ä¸»è¦å†…å®¹",
            f"{topic} {chapter_title} å…³é”®è¦ç‚¹", f"{topic} {chapter_title} æœ€æ–°å‘å±•",
            f"{topic} {chapter_title} é‡è¦æ€§"
        ]
        print(f"âš ï¸  ä½¿ç”¨é»˜è®¤æœç´¢æŸ¥è¯¢: {len(default_queries)} ä¸ª")
        for i, query in enumerate(default_queries, 1):
            print(f"  {i}. {query}")

        result = {
            "research_plan": f"ç ”ç©¶è®¡åˆ’ï¼šå¯¹ç« èŠ‚ {chapter_title} è¿›è¡Œæ·±å…¥ç ”ç©¶ï¼Œæ”¶é›†ç›¸å…³ä¿¡æ¯å¹¶æ•´ç†æˆæ–‡æ¡£ã€‚",
            "search_queries": default_queries
        }
        print(f"ğŸ“¤ PlannerèŠ‚ç‚¹è¿”å›é»˜è®¤ç»“æœ: {result}")
        return result


def researcher_node(state: ResearchState,
                    web_search_tool: WebSearchTool) -> dict:
    raise NotImplementedError("è¯·ä½¿ç”¨ async_researcher_node")


async def async_researcher_node(state: ResearchState,
                                web_search_tool: WebSearchTool,
                                es_search_tool: ESSearchTool,
                                reranker_tool: RerankerTool = None) -> dict:
    """
    å¼‚æ­¥èŠ‚ç‚¹2: æ‰§è¡Œæœç´¢ç ”ç©¶
    
    ä»çŠ¶æ€ä¸­è·å– search_queriesï¼Œä½¿ç”¨æœç´¢å·¥å…·æ”¶é›†ç›¸å…³ä¿¡æ¯
    ä¼˜å…ˆä½¿ç”¨å‘é‡æ£€ç´¢ï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€åˆ°æ–‡æœ¬æœç´¢
    ä½¿ç”¨é‡æ’åºå·¥å…·å¯¹æœç´¢ç»“æœè¿›è¡Œä¼˜åŒ–
    
    Args:
        state: ç ”ç©¶çŠ¶æ€ï¼ŒåŒ…å« search_queries
        web_search_tool: ç½‘ç»œæœç´¢å·¥å…·
        es_search_tool: Elasticsearchæœç´¢å·¥å…·
        reranker_tool: é‡æ’åºå·¥å…·ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        dict: åŒ…å« gathered_data çš„å­—å…¸
    """
    print(f"ğŸ” ResearcherèŠ‚ç‚¹æ¥æ”¶åˆ°çš„å®Œæ•´çŠ¶æ€:")
    print(f"  - topic: {state.get('topic', 'N/A')}")
    print(
        f"  - current_chapter_index: {state.get('current_chapter_index', 'N/A')}"
    )
    print(f"  - research_plan: {state.get('research_plan', 'N/A')[:100]}...")
    print(f"  - search_queries: {state.get('search_queries', [])}")
    print(f"  - search_queriesç±»å‹: {type(state.get('search_queries', []))}")
    print(f"  - search_queriesé•¿åº¦: {len(state.get('search_queries', []))}")
    print(f"  - gathered_data: {state.get('gathered_data', 'N/A')[:50]}...")

    search_queries = state.get("search_queries", [])

    if not search_queries:
        print("âŒ æ²¡æœ‰æœç´¢æŸ¥è¯¢ï¼Œè¿”å›é»˜è®¤æ¶ˆæ¯")
        return {"gathered_data": "æ²¡æœ‰æœç´¢æŸ¥è¯¢éœ€è¦æ‰§è¡Œ"}

    all_results = []

    # è·å–embeddingé…ç½®
    embedding_config = settings.supported_models.get("gte_qwen")
    embedding_client = None
    if embedding_config:
        try:
            embedding_client = EmbeddingClient(
                base_url=embedding_config.url,
                api_key=embedding_config.api_key)
            print("âœ… Embeddingå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸  Embeddingå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            embedding_client = None
    else:
        print("âŒ æœªæ‰¾åˆ° embedding é…ç½®ï¼Œå°†ä½¿ç”¨æ–‡æœ¬æœç´¢")

    # ä½¿ç”¨ä¼ å…¥çš„ESå·¥å…·ï¼Œä¸å†å†…éƒ¨åˆ›å»º
    for i, query in enumerate(search_queries, 1):
        print(f"æ‰§è¡Œæœç´¢æŸ¥è¯¢ {i}/{len(search_queries)}: {query}")

        # ç½‘ç»œæœç´¢
        web_results = ""
        try:
            web_results = web_search_tool.search(query)
            if "æ¨¡æ‹Ÿ" in web_results or "mock" in web_results.lower():
                print(f"ç½‘ç»œæœç´¢è¿”å›æ¨¡æ‹Ÿç»“æœï¼Œè·³è¿‡: {query}")
                web_results = ""
        except Exception as e:
            print(f"ç½‘ç»œæœç´¢å¤±è´¥: {str(e)}")
            web_results = ""

        # ESæœç´¢ - ä½¿ç”¨æ–°çš„æœç´¢å’Œé‡æ’åºåŠŸèƒ½
        es_results = ""
        try:
            if embedding_client:
                # å°è¯•å‘é‡æ£€ç´¢
                try:
                    embedding_response = embedding_client.invoke(query)
                    import json
                    try:
                        embedding_data = json.loads(embedding_response)
                        if isinstance(embedding_data, list):
                            if len(embedding_data) > 0 and isinstance(
                                    embedding_data[0], list):
                                query_vector = embedding_data[0]
                            else:
                                query_vector = embedding_data
                        elif isinstance(embedding_data,
                                        dict) and 'data' in embedding_data:
                            query_vector = embedding_data['data']
                        else:
                            print(
                                f"âš ï¸  æ— æ³•è§£æembeddingå“åº”æ ¼å¼: {type(embedding_data)}"
                            )
                            query_vector = None
                    except json.JSONDecodeError:
                        print(f"âš ï¸  JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨æ–‡æœ¬æœç´¢")
                        query_vector = None

                    if query_vector and len(query_vector) == 1536:
                        print(
                            f"âœ… å‘é‡ç»´åº¦: {len(query_vector)}ï¼Œå‰5: {query_vector[:5]}"
                        )
                        # ä½¿ç”¨æ–°çš„æœç´¢å’Œé‡æ’åºåŠŸèƒ½
                        search_query = query if query.strip() else "ç›¸å…³æ–‡æ¡£"
                        _, reranked_results, formatted_es_results = await search_and_rerank(
                            es_search_tool=es_search_tool,
                            query=search_query,
                            query_vector=query_vector,
                            reranker_tool=reranker_tool,
                            initial_top_k=10,  # åˆå§‹æœç´¢è¿”å›æ›´å¤šç»“æœ
                            final_top_k=5  # é‡æ’åºåè¿”å›top5
                        )
                        es_results = formatted_es_results
                        print(
                            f"âœ… å‘é‡æ£€ç´¢+é‡æ’åºæ‰§è¡ŒæˆåŠŸï¼Œç»“æœé•¿åº¦: {len(formatted_es_results)}"
                        )
                    else:
                        print(f"âŒ å‘é‡ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨æ–‡æœ¬æœç´¢")
                        # å›é€€åˆ°æ–‡æœ¬æœç´¢
                        _, reranked_results, formatted_es_results = await search_and_rerank(
                            es_search_tool=es_search_tool,
                            query=query,
                            query_vector=None,
                            reranker_tool=reranker_tool,
                            initial_top_k=10,
                            final_top_k=5)
                        es_results = formatted_es_results
                        print(
                            f"âœ… æ–‡æœ¬æœç´¢+é‡æ’åºæ‰§è¡ŒæˆåŠŸï¼Œç»“æœé•¿åº¦: {len(formatted_es_results)}"
                        )
                except Exception as e:
                    print(f"âŒ å‘é‡æ£€ç´¢å¼‚å¸¸: {str(e)}ï¼Œä½¿ç”¨æ–‡æœ¬æœç´¢")
                    # å›é€€åˆ°æ–‡æœ¬æœç´¢
                    _, reranked_results, formatted_es_results = await search_and_rerank(
                        es_search_tool=es_search_tool,
                        query=query,
                        query_vector=None,
                        reranker_tool=reranker_tool,
                        initial_top_k=10,
                        final_top_k=5)
                    es_results = formatted_es_results
                    print(f"âœ… æ–‡æœ¬æœç´¢+é‡æ’åºæ‰§è¡ŒæˆåŠŸï¼Œç»“æœé•¿åº¦: {len(formatted_es_results)}")
            else:
                # æ²¡æœ‰embeddingå®¢æˆ·ç«¯ï¼Œç›´æ¥ä½¿ç”¨æ–‡æœ¬æœç´¢
                print("ğŸ“ ä½¿ç”¨æ–‡æœ¬æœç´¢")
                _, reranked_results, formatted_es_results = await search_and_rerank(
                    es_search_tool=es_search_tool,
                    query=query,
                    query_vector=None,
                    reranker_tool=reranker_tool,
                    initial_top_k=10,
                    final_top_k=5)
                es_results = formatted_es_results
                print(f"âœ… æ–‡æœ¬æœç´¢+é‡æ’åºæ‰§è¡ŒæˆåŠŸï¼Œç»“æœé•¿åº¦: {len(formatted_es_results)}")

        except Exception as e:
            print(f"âŒ ESæœç´¢å¤±è´¥: {str(e)}")
            es_results = f"ESæœç´¢å¤±è´¥: {str(e)}"

        # èšåˆç»“æœ
        query_results = f"=== æœç´¢æŸ¥è¯¢ {i}: {query} ===\n\n"
        if web_results:
            query_results += f"ç½‘ç»œæœç´¢ç»“æœ:\n{web_results}\n\n"
        if es_results:
            query_results += f"çŸ¥è¯†åº“æœç´¢ç»“æœ:\n{es_results}\n\n"
        if not web_results and not es_results:
            query_results += "æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœ\n\n"
        all_results.append(query_results)

    # åˆå¹¶æ‰€æœ‰æœç´¢ç»“æœ
    if all_results:
        gathered_data = "\\n\\n".join(all_results)
        print(f"âœ… æ”¶é›†åˆ° {len(all_results)} æ¡æœç´¢ç»“æœ")
        print(f"ğŸ“Š æ€»æ•°æ®é•¿åº¦: {len(gathered_data)} å­—ç¬¦")
        # åªæ˜¾ç¤ºå‰200å­—ç¬¦ä½œä¸ºé¢„è§ˆï¼Œé¿å…æ—¥å¿—è¿‡é•¿
        preview = gathered_data[:200] + "..." if len(
            gathered_data) > 200 else gathered_data
        print(f"ğŸ“ æ•°æ®é¢„è§ˆ: {preview}")
    else:
        gathered_data = "æœªæ”¶é›†åˆ°ä»»ä½•æœç´¢ç»“æœ"
        print("âŒ æœªæ”¶é›†åˆ°ä»»ä½•æœç´¢ç»“æœ")

    return {"gathered_data": gathered_data}


def writer_node(state: ResearchState, llm_client: LLMClient) -> dict:
    """
    ç« èŠ‚å†™ä½œèŠ‚ç‚¹
    
    åŸºäºå½“å‰ç« èŠ‚çš„ç ”ç©¶æ•°æ®å’Œå·²å®Œæˆç« èŠ‚çš„ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆå½“å‰ç« èŠ‚çš„å†…å®¹
    
    Args:
        state: ç ”ç©¶çŠ¶æ€ï¼ŒåŒ…å«ç« èŠ‚ä¿¡æ¯ã€ç ”ç©¶æ•°æ®å’Œå·²å®Œæˆç« èŠ‚
        llm_client: LLMå®¢æˆ·ç«¯å®ä¾‹
        
    Returns:
        dict: åŒ…å«å½“å‰ç« èŠ‚å†…å®¹çš„å­—å…¸
    """
    # è·å–åŸºæœ¬ä¿¡æ¯
    topic = state.get("topic", "")
    current_chapter_index = state.get("current_chapter_index", 0)
    chapters_to_process = state.get("chapters_to_process", [])
    completed_chapters_content = state.get("completed_chapters_content", [])

    # éªŒè¯å½“å‰ç« èŠ‚ç´¢å¼•
    if current_chapter_index >= len(chapters_to_process):
        raise ValueError(f"ç« èŠ‚ç´¢å¼• {current_chapter_index} è¶…å‡ºèŒƒå›´")

    # è·å–å½“å‰ç« èŠ‚ä¿¡æ¯
    current_chapter = chapters_to_process[current_chapter_index]
    chapter_title = current_chapter.get("chapter_title", "")
    chapter_description = current_chapter.get("description", "")

    # ä»çŠ¶æ€ä¸­è·å–ç ”ç©¶æ•°æ®
    gathered_data = state.get("gathered_data", "")

    if not chapter_title:
        raise ValueError("ç« èŠ‚æ ‡é¢˜ä¸èƒ½ä¸ºç©º")

    if not gathered_data:
        return {
            "final_document": f"## {chapter_title}\n\nç”±äºæ²¡æœ‰æ”¶é›†åˆ°ç›¸å…³æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆç« èŠ‚å†…å®¹ã€‚"
        }

    # è·å–æ–‡æ¡£ç”Ÿæˆå™¨é…ç½®
    document_writer_config = settings.get_agent_component_config(
        "document_writer")
    if not document_writer_config:
        temperature = 0.7
        max_tokens = 4000
        extra_params = {}
    else:
        temperature = document_writer_config.temperature
        max_tokens = document_writer_config.max_tokens
        extra_params = document_writer_config.extra_params

    # æ„å»ºå·²å®Œæˆç« èŠ‚çš„ä¸Šä¸‹æ–‡æ‘˜è¦
    previous_chapters_context = ""
    if completed_chapters_content:
        previous_chapters_context = "\n\n".join([
            f"ç¬¬{i+1}ç« æ‘˜è¦:\n{content[:500]}..."
            if len(content) > 500 else f"ç¬¬{i+1}ç« :\n{content}"
            for i, content in enumerate(completed_chapters_content)
        ])

    # æ„å»ºé«˜è´¨é‡çš„æç¤ºè¯
    prompt = f"""
**è§’è‰²:** ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç ”ç©¶å‘˜å’Œæ–‡æ¡£æ’°å†™ä¸“å®¶ï¼Œè´Ÿè´£æ’°å†™é«˜è´¨é‡çš„ç« èŠ‚å†…å®¹ã€‚

**æ–‡æ¡£ä¸»é¢˜:** {topic}

**å½“å‰ç« èŠ‚ä¿¡æ¯:**
- ç« èŠ‚æ ‡é¢˜: {chapter_title}
- ç« èŠ‚æè¿°: {chapter_description}
- ç« èŠ‚åºå·: ç¬¬{current_chapter_index + 1}ç« ï¼ˆå…±{len(chapters_to_process)}ç« ï¼‰

**å·²å®Œæˆçš„ç« èŠ‚å†…å®¹ï¼ˆç”¨äºä¿æŒè¿è´¯æ€§ï¼‰:**
{previous_chapters_context if previous_chapters_context else "è¿™æ˜¯ç¬¬ä¸€ç« ï¼Œæ²¡æœ‰å‰ç½®å†…å®¹ã€‚"}

**å½“å‰ç« èŠ‚çš„ç ”ç©¶æ•°æ®:**
{gathered_data}

**å†™ä½œä»»åŠ¡:**
åŸºäºæä¾›çš„ç ”ç©¶æ•°æ®ï¼Œä¸ºå½“å‰ç« èŠ‚æ’°å†™å†…å®¹ã€‚è¯·éµå¾ªä»¥ä¸‹è¦æ±‚ï¼š

1. **ä¿æŒè¿è´¯æ€§:** ç¡®ä¿å½“å‰ç« èŠ‚ä¸å·²å®Œæˆçš„ç« èŠ‚å†…å®¹è‡ªç„¶è¡”æ¥ï¼Œé¿å…é‡å¤ï¼Œä¿æŒé€»è¾‘è¿è´¯ã€‚

2. **ç« èŠ‚ç»“æ„:** 
   - ä»¥äºŒçº§æ ‡é¢˜ï¼ˆ##ï¼‰å¼€å§‹ï¼Œä½¿ç”¨ç« èŠ‚æ ‡é¢˜
   - åŒ…å«é€‚å½“çš„å¼•è¨€ï¼Œè¯´æ˜æœ¬ç« èŠ‚çš„ä¸»è¦å†…å®¹
   - ä½¿ç”¨ä¸‰çº§æ ‡é¢˜ï¼ˆ###ï¼‰ç»„ç»‡å­èŠ‚
   - åœ¨ç« èŠ‚æœ«å°¾æä¾›ç®€çŸ­çš„è¿‡æ¸¡ï¼Œä¸ºä¸‹ä¸€ç« èŠ‚åšå‡†å¤‡ï¼ˆå¦‚æœä¸æ˜¯æœ€åä¸€ç« ï¼‰

3. **å†…å®¹è¦æ±‚:**
   - ç»¼åˆåˆ†æç ”ç©¶æ•°æ®ï¼Œä¸è¦ç®€å•ç½—åˆ—
   - ä¿æŒå®¢è§‚ï¼ŒåŸºäºäº‹å®
   - ä½¿ç”¨ä¸“ä¸šçš„å­¦æœ¯å†™ä½œé£æ ¼
   - é€‚å½“å¼•ç”¨å·²å®Œæˆç« èŠ‚çš„å†…å®¹ä»¥ä¿æŒè¿è´¯æ€§

4. **æ ¼å¼è¦æ±‚:**
   - ä½¿ç”¨Markdownæ ¼å¼
   - é€‚å½“ä½¿ç”¨åˆ—è¡¨ã€è¡¨æ ¼ã€å¼•ç”¨ç­‰æ ¼å¼å…ƒç´ 
   - ä»£ç æˆ–æŠ€æœ¯è§„èŒƒä½¿ç”¨ä»£ç å—
   - é‡è¦è§‚ç‚¹ä½¿ç”¨ç²—ä½“å¼ºè°ƒ

5. **ç¯‡å¹…æ§åˆ¶:**
   - ç« èŠ‚å†…å®¹åº”è¯¥å……å®ä½†ä¸å†—é•¿
   - æ ¹æ®ç ”ç©¶æ•°æ®çš„ä¸°å¯Œç¨‹åº¦è°ƒæ•´ç¯‡å¹…
   - ä¸€èˆ¬æ¯ç« 2000-4000å­—ä¸ºå®œ

è¯·ç«‹å³å¼€å§‹æ’°å†™å½“å‰ç« èŠ‚çš„å†…å®¹ã€‚
"""

    # é™åˆ¶ prompt é•¿åº¦
    max_prompt_length = 30000
    if len(prompt) > max_prompt_length:
        print(
            f"âš ï¸  Writer prompt é•¿åº¦ {len(prompt)} è¶…è¿‡é™åˆ¶ {max_prompt_length}ï¼Œè¿›è¡Œæˆªæ–­"
        )

        # ä¼˜å…ˆä¿ç•™å½“å‰ç« èŠ‚çš„ç ”ç©¶æ•°æ®ï¼Œé€‚å½“ç¼©å‡å·²å®Œæˆç« èŠ‚çš„ä¸Šä¸‹æ–‡
        if len(previous_chapters_context) > 5000:
            # åªä¿ç•™æ¯ç« çš„ç®€çŸ­æ‘˜è¦
            previous_chapters_context = "\n\n".join([
                f"ç¬¬{i+1}ç« æ‘˜è¦:\n{content[:200]}..."
                for i, content in enumerate(completed_chapters_content)
            ])

        # å¦‚æœç ”ç©¶æ•°æ®ä¹Ÿå¤ªé•¿ï¼Œè¿›è¡Œæˆªæ–­
        if len(gathered_data) > 15000:
            gathered_data = gathered_data[:15000] + "\n\n... (ç ”ç©¶æ•°æ®å·²æˆªæ–­)"

        # é‡æ–°æ„å»ºprompt
        prompt = f"""
**è§’è‰²:** ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç ”ç©¶å‘˜å’Œæ–‡æ¡£æ’°å†™ä¸“å®¶ï¼Œè´Ÿè´£æ’°å†™é«˜è´¨é‡çš„ç« èŠ‚å†…å®¹ã€‚

**æ–‡æ¡£ä¸»é¢˜:** {topic}

**å½“å‰ç« èŠ‚ä¿¡æ¯:**
- ç« èŠ‚æ ‡é¢˜: {chapter_title}
- ç« èŠ‚æè¿°: {chapter_description}
- ç« èŠ‚åºå·: ç¬¬{current_chapter_index + 1}ç« ï¼ˆå…±{len(chapters_to_process)}ç« ï¼‰

**å·²å®Œæˆçš„ç« èŠ‚å†…å®¹ï¼ˆæ‘˜è¦ï¼‰:**
{previous_chapters_context if previous_chapters_context else "è¿™æ˜¯ç¬¬ä¸€ç« ï¼Œæ²¡æœ‰å‰ç½®å†…å®¹ã€‚"}

**å½“å‰ç« èŠ‚çš„ç ”ç©¶æ•°æ®:**
{gathered_data}

**å†™ä½œä»»åŠ¡:**
åŸºäºç ”ç©¶æ•°æ®æ’°å†™å½“å‰ç« èŠ‚ï¼Œç¡®ä¿ä¸å‰é¢ç« èŠ‚è¿è´¯ï¼Œä½¿ç”¨Markdownæ ¼å¼ï¼Œä»¥##å¼€å§‹ç« èŠ‚æ ‡é¢˜ã€‚
"""
        print(f"ğŸ“ æˆªæ–­å writer prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")

    try:
        # è°ƒç”¨LLMç”Ÿæˆç« èŠ‚å†…å®¹
        response = llm_client.invoke(prompt,
                                     temperature=temperature,
                                     max_tokens=max_tokens,
                                     **extra_params)

        # ç¡®ä¿å“åº”æ ¼å¼æ­£ç¡®
        if not response.strip():
            response = f"## {chapter_title}\n\næ— æ³•ç”Ÿæˆç« èŠ‚å†…å®¹ã€‚"
        elif not response.startswith("##"):
            # å¦‚æœæ²¡æœ‰äºŒçº§æ ‡é¢˜ï¼Œæ·»åŠ ç« èŠ‚æ ‡é¢˜
            response = f"## {chapter_title}\n\n{response}"

        # è¿”å›å½“å‰ç« èŠ‚çš„å†…å®¹
        return {"final_document": response}

    except Exception as e:
        # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
        print(f"Writer node error: {str(e)}")
        error_content = f"""## {chapter_title}

### ç« èŠ‚ç”Ÿæˆé”™è¯¯

ç”±äºæŠ€æœ¯åŸå› ï¼Œæ— æ³•ç”Ÿæˆæœ¬ç« èŠ‚çš„å†…å®¹ã€‚

**é”™è¯¯ä¿¡æ¯:** {str(e)}

**ç« èŠ‚æè¿°:** {chapter_description}

è¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®æˆ–ç¨åé‡è¯•ã€‚
"""
        return {"final_document": error_content}
