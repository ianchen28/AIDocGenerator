"""
ç”ŸæˆèŠ‚ç‚¹æ¨¡å—

è´Ÿè´£å¤§çº²ç”Ÿæˆã€ç« èŠ‚æ‹†åˆ†ã€å‚è€ƒæ–‡çŒ®ç”Ÿæˆç­‰åŠŸèƒ½
"""

import json
from loguru import logger

from doc_agent.core.config import settings
from doc_agent.graph.state import ResearchState
from doc_agent.llm_clients.base import LLMClient
from doc_agent.common.prompt_selector import PromptSelector
from doc_agent.schemas import Source
from doc_agent.graph.common import format_sources_to_text


def outline_generation_node(state: ResearchState,
                            llm_client: LLMClient,
                            prompt_selector: PromptSelector = None,
                            genre: str = "default") -> dict:
    """
    å¤§çº²ç”ŸæˆèŠ‚ç‚¹ - ç»Ÿä¸€ç‰ˆæœ¬
    æ ¹æ®åˆå§‹ç ”ç©¶æ•°æ®ç”Ÿæˆæ–‡æ¡£å¤§çº²
    æ”¯æŒåŸºäºé…ç½®çš„è¡Œä¸ºè°ƒæ•´
    
    Args:
        state: ç ”ç©¶çŠ¶æ€
        llm_client: LLMå®¢æˆ·ç«¯
        prompt_selector: æç¤ºè¯é€‰æ‹©å™¨
        genre: æ–‡æ¡£ç±»å‹
        
    Returns:
        dict: åŒ…å« document_outline çš„å­—å…¸
    """
    topic = state.get("topic", "")
    initial_sources = state.get("initial_sources", [])

    if not topic:
        raise ValueError("ä¸»é¢˜ä¸èƒ½ä¸ºç©º")

    # è·å–å¤æ‚åº¦é…ç½®
    complexity_config = settings.get_complexity_config()
    logger.info(f"ğŸ“‹ å¼€å§‹ç”Ÿæˆå¤§çº² (æ¨¡å¼: {complexity_config['level']}): {topic}")

    # æ ¼å¼åŒ–æ•°æ®
    if initial_sources:
        initial_gathered_data = format_sources_to_text(initial_sources)
    else:
        initial_gathered_data = state.get("initial_gathered_data", "")

    if not initial_gathered_data:
        logger.warning("æ²¡æœ‰åˆå§‹ç ”ç©¶æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å¤§çº²")
        return _generate_default_outline(topic, complexity_config)

    # è·å–æç¤ºè¯æ¨¡æ¿
    prompt_template = _get_outline_prompt_template(complexity_config,
                                                   prompt_selector, genre)

    # æ„å»ºæç¤ºè¯
    prompt = prompt_template.format(
        topic=topic,
        initial_gathered_data=initial_gathered_data[:5000]  # é™åˆ¶é•¿åº¦
    )

    try:
        # æ ¹æ®å¤æ‚åº¦è°ƒæ•´å‚æ•°
        temperature = 0.7
        max_tokens = 2000

        response = llm_client.invoke(prompt,
                                     temperature=temperature,
                                     max_tokens=max_tokens)

        # è§£æå“åº”
        outline = _parse_outline_response(response, complexity_config)

        logger.info(f"âœ… å¤§çº²ç”Ÿæˆå®Œæˆï¼ŒåŒ…å« {len(outline.get('chapters', []))} ä¸ªç« èŠ‚")

        return {"document_outline": outline}

    except Exception as e:
        logger.error(f"å¤§çº²ç”Ÿæˆå¤±è´¥: {str(e)}")
        return _generate_default_outline(topic, complexity_config)


def split_chapters_node(state: ResearchState) -> dict:
    """
    ç« èŠ‚æ‹†åˆ†èŠ‚ç‚¹ - ç»Ÿä¸€ç‰ˆæœ¬
    å°†æ–‡æ¡£å¤§çº²æ‹†åˆ†ä¸ºç‹¬ç«‹çš„ç« èŠ‚ä»»åŠ¡åˆ—è¡¨
    æ ¹æ®é…ç½®é™åˆ¶ç« èŠ‚æ•°é‡
    """
    document_outline = state.get("document_outline", {})

    if not document_outline or "chapters" not in document_outline:
        raise ValueError("æ–‡æ¡£å¤§çº²ä¸å­˜åœ¨æˆ–æ ¼å¼æ— æ•ˆ")

    # è·å–å¤æ‚åº¦é…ç½®
    complexity_config = settings.get_complexity_config()
    max_chapters = complexity_config.get('max_chapters', -1)

    logger.info(f"ğŸ“‚ å¼€å§‹æ‹†åˆ†ç« èŠ‚ä»»åŠ¡ (æ¨¡å¼: {complexity_config['level']})")

    # ä»å¤§çº²ä¸­æå–ç« èŠ‚ä¿¡æ¯
    chapters = document_outline.get("chapters", [])

    # æ ¹æ®é…ç½®é™åˆ¶ç« èŠ‚æ•°é‡
    if max_chapters > 0:
        chapters = chapters[:max_chapters]
        logger.info(f"ğŸ”§ é™åˆ¶ç« èŠ‚æ•°é‡ä¸º {len(chapters)} ä¸ª")

    # åˆ›å»ºç« èŠ‚ä»»åŠ¡åˆ—è¡¨
    chapters_to_process = []
    for chapter in chapters:
        # æ ¹æ®å¤æ‚åº¦è°ƒæ•´é¢„ä¼°ç« èŠ‚æ•°
        estimated_sections = 2 if complexity_config[
            'level'] == 'fast' else chapter.get("estimated_sections", 3)

        chapter_task = {
            "chapter_number":
            chapter.get("chapter_number",
                        len(chapters_to_process) + 1),
            "chapter_title":
            chapter.get("chapter_title", f"ç¬¬{len(chapters_to_process) + 1}ç« "),
            "description":
            chapter.get("description", ""),
            "key_points":
            chapter.get("key_points", []),
            "estimated_sections":
            estimated_sections,
            "research_data":
            ""
        }
        chapters_to_process.append(chapter_task)

    logger.info(f"âœ… æˆåŠŸåˆ›å»º {len(chapters_to_process)} ä¸ªç« èŠ‚ä»»åŠ¡")

    # æ‰“å°ç« èŠ‚åˆ—è¡¨
    for chapter in chapters_to_process:
        logger.info(
            f"  ğŸ“„ ç¬¬{chapter['chapter_number']}ç« : {chapter['chapter_title']}")

    return {
        "chapters_to_process": chapters_to_process,
        "current_chapter_index": 0,
        "completed_chapters": []
    }


def bibliography_node(state: ResearchState) -> dict:
    """
    å‚è€ƒæ–‡çŒ®ç”ŸæˆèŠ‚ç‚¹
    æ ¹æ®å…¨å±€å¼•ç”¨æºç”Ÿæˆå‚è€ƒæ–‡çŒ®åˆ—è¡¨
    """
    cited_sources = state.get("cited_sources", {})

    logger.info(f"ğŸ“š å¼€å§‹ç”Ÿæˆå‚è€ƒæ–‡çŒ®ï¼Œå…± {len(cited_sources)} ä¸ªå¼•ç”¨æº")

    if not cited_sources:
        logger.warning("æ²¡æœ‰å¼•ç”¨æºï¼Œç”Ÿæˆç©ºçš„å‚è€ƒæ–‡çŒ®")
        bibliography = "\n## å‚è€ƒæ–‡çŒ®\n\næš‚æ— å‚è€ƒæ–‡çŒ®ã€‚\n"
    else:
        # ç”Ÿæˆå‚è€ƒæ–‡çŒ®
        bibliography_lines = ["\n## å‚è€ƒæ–‡çŒ®\n"]

        # æŒ‰IDæ’åº
        sorted_sources = sorted(cited_sources.items(), key=lambda x: x[0])

        for source_id, source in sorted_sources:
            citation = _format_citation(source_id, source)
            bibliography_lines.append(citation)

        bibliography = "\n".join(bibliography_lines)

        logger.info(f"âœ… å‚è€ƒæ–‡çŒ®ç”Ÿæˆå®Œæˆï¼ŒåŒ…å« {len(sorted_sources)} æ¡å¼•ç”¨")

    # è·å–ç°æœ‰çš„ final_document
    final_document = state.get("final_document", "")

    # å°†å‚è€ƒæ–‡çŒ®æ·»åŠ åˆ°æœ€ç»ˆæ–‡æ¡£ä¸­
    updated_final_document = final_document + bibliography

    logger.info(f"ğŸ“š å·²å°†å‚è€ƒæ–‡çŒ®æ·»åŠ åˆ°æœ€ç»ˆæ–‡æ¡£ä¸­ï¼Œæ€»é•¿åº¦: {len(updated_final_document)} å­—ç¬¦")

    # è¿”å›æ›´æ–°åçš„ final_document
    return {"final_document": updated_final_document}


def _get_outline_prompt_template(complexity_config, prompt_selector, genre):
    """è·å–å¤§çº²ç”Ÿæˆçš„æç¤ºè¯æ¨¡æ¿"""
    try:
        if complexity_config['use_simplified_prompts']:
            # å¿«é€Ÿæ¨¡å¼ä½¿ç”¨ç®€åŒ–æç¤ºè¯
            from doc_agent.fast_prompts import FAST_OUTLINE_GENERATION_PROMPT
            return FAST_OUTLINE_GENERATION_PROMPT

        # æ ‡å‡†æ¨¡å¼ä½¿ç”¨å®Œæ•´æç¤ºè¯
        if prompt_selector:
            return prompt_selector.get_prompt("main_orchestrator", "outline",
                                              genre)

    except Exception as e:
        logger.error(f"è·å–æç¤ºè¯æ¨¡æ¿å¤±è´¥: {e}")

    # å¤‡ç”¨æ¨¡æ¿
    return """
åŸºäºä»¥ä¸‹ç ”ç©¶æ•°æ®ï¼Œä¸ºä¸»é¢˜"{topic}"ç”Ÿæˆè¯¦ç»†çš„æ–‡æ¡£å¤§çº²ã€‚

ç ”ç©¶æ•°æ®ï¼š
{initial_gathered_data}

è¯·ç”ŸæˆJSONæ ¼å¼çš„å¤§çº²ï¼ŒåŒ…å«ï¼š
- title: æ–‡æ¡£æ ‡é¢˜
- summary: æ–‡æ¡£æ‘˜è¦
- chapters: ç« èŠ‚åˆ—è¡¨ï¼Œæ¯ä¸ªç« èŠ‚åŒ…å« chapter_number, chapter_title, description, key_points

è¾“å‡ºJSONæ ¼å¼çš„å¤§çº²ã€‚
"""


def _parse_outline_response(response: str, complexity_config) -> dict:
    """è§£æå¤§çº²ç”Ÿæˆå“åº”"""
    # æ¸…é™¤æ”¶å°¾çš„ ```json å’Œ ```
    response = response.replace('```json', '').replace('```', '').strip()
    #
    try:
        # å°è¯•è§£æJSON
        import re
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if json_match:
            outline = json.loads(json_match.group(0))

            # æ ¹æ®å¤æ‚åº¦é™åˆ¶ç« èŠ‚æ•°é‡
            max_chapters = complexity_config.get('max_chapters', -1)
            if max_chapters > 0 and 'chapters' in outline:
                outline['chapters'] = outline['chapters'][:max_chapters]

            return outline
    except Exception as e:
        logger.error(f"è§£æå¤§çº²å“åº”å¤±è´¥: {e}")

    # è¿”å›é»˜è®¤å¤§çº²
    return _generate_default_outline("æœªçŸ¥ä¸»é¢˜", complexity_config)


def _generate_default_outline(topic: str, complexity_config) -> dict:
    """ç”Ÿæˆé»˜è®¤å¤§çº²"""
    max_chapters = complexity_config.get('max_chapters', 3)
    if max_chapters <= 0:
        max_chapters = 3

    # æ ¹æ®ä¸»é¢˜ç”Ÿæˆæ›´åˆé€‚çš„å¤§çº²
    if "æ°´ç”µç«™" in topic or "æ°´ç”µ" in topic:
        chapters = [{
            "chapter_number": 1,
            "chapter_title": "æ°´ç”µç«™å»ºé€ æ¦‚è¿°",
            "description": "ä»‹ç»æ°´ç”µç«™å»ºé€ çš„åŸºæœ¬æ¦‚å¿µã€é‡è¦æ€§å’ŒæŠ€æœ¯ç‰¹ç‚¹",
            "key_points": ["æ°´ç”µç«™ç±»å‹", "å»ºé€ æµç¨‹", "æŠ€æœ¯æ ‡å‡†"]
        }, {
            "chapter_number": 2,
            "chapter_title": "å»ºé€ è¿‡ç¨‹ä¸­çš„ä¸»è¦é—®é¢˜",
            "description": "è¯¦ç»†åˆ†ææ°´ç”µç«™å»ºé€ è¿‡ç¨‹ä¸­å¯èƒ½é‡åˆ°çš„æŠ€æœ¯å’Œç®¡ç†é—®é¢˜",
            "key_points": ["åœ°è´¨é—®é¢˜", "æŠ€æœ¯éš¾é¢˜", "ç®¡ç†æŒ‘æˆ˜"]
        }, {
            "chapter_number": 3,
            "chapter_title": "è§£å†³æ–¹æ¡ˆä¸æœ€ä½³å®è·µ",
            "description": "æä¾›é’ˆå¯¹å„ç±»é—®é¢˜çš„è§£å†³æ–¹æ¡ˆå’Œè¡Œä¸šæœ€ä½³å®è·µ",
            "key_points": ["æŠ€æœ¯æ–¹æ¡ˆ", "ç®¡ç†æªæ–½", "é¢„é˜²ç­–ç•¥"]
        }]
    else:
        # é€šç”¨å¤§çº²
        chapters = []
        for i in range(min(max_chapters, 3)):
            chapters.append({
                "chapter_number": i + 1,
                "chapter_title": f"{topic} - ç¬¬{i + 1}éƒ¨åˆ†",
                "description": f"å…³äº{topic}çš„ç¬¬{i + 1}éƒ¨åˆ†å†…å®¹",
                "key_points": [f"{topic}ç›¸å…³è¦ç‚¹"]
            })

    return {
        "title": f"{topic} ç ”ç©¶æŠ¥å‘Š",
        "summary": f"æœ¬æ–‡æ¡£æ·±å…¥æ¢è®¨äº†{topic}çš„ç›¸å…³å†…å®¹ï¼ŒåŒ…æ‹¬é—®é¢˜åˆ†æå’Œè§£å†³æ–¹æ¡ˆã€‚",
        "chapters": chapters[:max_chapters]  # ç¡®ä¿ä¸è¶…è¿‡æœ€å¤§ç« èŠ‚æ•°
    }


def _format_citation(source_id: int, source: Source) -> str:
    """æ ¼å¼åŒ–å•ä¸ªå¼•ç”¨"""
    citation = f"[{source_id}] {source.title}"

    if source.url:
        citation += f" - {source.url}"

    citation += f" ({source.source_type})"

    return citation
