# service/src/doc_agent/utils/content_processor.py
from typing import List, Dict, Any
import json
from ..llm_clients.base import LLMClient


def summarize_content(content: str,
                      llm_client: LLMClient,
                      max_length: int = 2000) -> str:
    """
    ç¼©å†™å†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯
    
    Args:
        content: åŸå§‹å†…å®¹
        llm_client: LLMå®¢æˆ·ç«¯
        max_length: ç›®æ ‡é•¿åº¦
        
    Returns:
        str: ç¼©å†™åçš„å†…å®¹
    """
    if len(content) <= max_length:
        return content

    prompt = f"""
è¯·å°†ä»¥ä¸‹å†…å®¹ç¼©å†™åˆ° {max_length} å­—ç¬¦ä»¥å†…ï¼Œä¿ç•™å…³é”®ä¿¡æ¯å’Œè¦ç‚¹ï¼š

{content[:8000]}  # é™åˆ¶è¾“å…¥é•¿åº¦

è¦æ±‚ï¼š
1. ä¿ç•™æ ¸å¿ƒè§‚ç‚¹å’Œé‡è¦äº‹å®
2. åˆ é™¤å†—ä½™å’Œé‡å¤ä¿¡æ¯
3. ä½¿ç”¨ç®€æ´æ˜äº†çš„è¯­è¨€
4. ä¿æŒé€»è¾‘ç»“æ„æ¸…æ™°
5. ç¡®ä¿ç¼©å†™åçš„å†…å®¹ä»ç„¶æœ‰ä»·å€¼

è¯·ç›´æ¥è¿”å›ç¼©å†™åçš„å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜ã€‚
"""

    try:
        response = llm_client.invoke(prompt,
                                     temperature=0.3,
                                     max_tokens=min(max_length * 2, 4000))
        return response.strip()
    except Exception as e:
        print(f"âš ï¸  å†…å®¹ç¼©å†™å¤±è´¥: {str(e)}")
        # ç®€å•çš„æˆªæ–­ä½œä¸ºåå¤‡æ–¹æ¡ˆ
        return content[:max_length] + "..."


def extract_key_points(content: str,
                       llm_client: LLMClient,
                       num_points: int = 5) -> List[str]:
    """
    ä»å†…å®¹ä¸­æå–å…³é”®è¦ç‚¹
    
    Args:
        content: åŸå§‹å†…å®¹
        llm_client: LLMå®¢æˆ·ç«¯
        num_points: è¦ç‚¹æ•°é‡
        
    Returns:
        List[str]: å…³é”®è¦ç‚¹åˆ—è¡¨
    """
    prompt = f"""
è¯·ä»ä»¥ä¸‹å†…å®¹ä¸­æå– {num_points} ä¸ªæœ€é‡è¦çš„å…³é”®è¦ç‚¹ï¼š

{content[:6000]}  # é™åˆ¶è¾“å…¥é•¿åº¦

è¦æ±‚ï¼š
1. æå–æœ€æ ¸å¿ƒã€æœ€é‡è¦çš„ä¿¡æ¯
2. æ¯ä¸ªè¦ç‚¹åº”è¯¥æ˜¯ä¸€ä¸ªå®Œæ•´çš„è§‚ç‚¹
3. è¦ç‚¹ä¹‹é—´åº”è¯¥æœ‰é€»è¾‘å…³è”
4. ä½¿ç”¨ç®€æ´æ˜äº†çš„è¡¨è¾¾

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3", "è¦ç‚¹4", "è¦ç‚¹5"]
}}
"""

    try:
        response = llm_client.invoke(prompt, temperature=0.3, max_tokens=1000)

        # è§£æJSONå“åº”
        cleaned_response = response.strip()
        if cleaned_response.startswith("```json"):
            cleaned_response = cleaned_response[7:]
        if cleaned_response.startswith("```"):
            cleaned_response = cleaned_response[3:]
        if cleaned_response.endswith("```"):
            cleaned_response = cleaned_response[:-3]

        try:
            data = json.loads(cleaned_response.strip())
            return data.get("key_points", [])
        except Exception as json_err:
            print(f"âš ï¸  å…³é”®è¦ç‚¹æå–å¤±è´¥: JSONè§£æé”™è¯¯: {json_err}")
            print(f"âš ï¸  LLMåŸå§‹å“åº”: {repr(response)}")
            # ç®€å•çš„åå¤‡æ–¹æ¡ˆ
            return [f"è¦ç‚¹{i+1}" for i in range(num_points)]

    except Exception as e:
        print(f"âš ï¸  å…³é”®è¦ç‚¹æå–å¤±è´¥: {str(e)}")
        # ç®€å•çš„åå¤‡æ–¹æ¡ˆ
        return [f"è¦ç‚¹{i+1}" for i in range(num_points)]


def expand_content(content: str,
                   llm_client: LLMClient,
                   target_length: int = 3000) -> str:
    """
    æ‰©å†™å†…å®¹ï¼Œå¢åŠ è¯¦ç»†ç¨‹åº¦
    
    Args:
        content: åŸå§‹å†…å®¹
        llm_client: LLMå®¢æˆ·ç«¯
        target_length: ç›®æ ‡é•¿åº¦
        
    Returns:
        str: æ‰©å†™åçš„å†…å®¹
    """
    if len(content) >= target_length:
        return content

    prompt = f"""
è¯·å°†ä»¥ä¸‹å†…å®¹æ‰©å†™åˆ° {target_length} å­—ç¬¦å·¦å³ï¼Œå¢åŠ è¯¦ç»†ç¨‹åº¦å’Œæ·±åº¦ï¼š

{content}

è¦æ±‚ï¼š
1. ä¿æŒåŸæœ‰æ ¸å¿ƒè§‚ç‚¹ä¸å˜
2. å¢åŠ å…·ä½“çš„ä¾‹å­å’Œè¯´æ˜
3. æ·»åŠ ç›¸å…³çš„èƒŒæ™¯ä¿¡æ¯
4. ä½¿ç”¨æ›´ä¸°å¯Œçš„è¡¨è¾¾æ–¹å¼
5. ç¡®ä¿æ‰©å†™åçš„å†…å®¹æœ‰ä»·å€¼

è¯·ç›´æ¥è¿”å›æ‰©å†™åçš„å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜ã€‚
"""

    try:
        response = llm_client.invoke(prompt,
                                     temperature=0.7,
                                     max_tokens=min(target_length * 2, 6000))
        return response.strip()
    except Exception as e:
        print(f"âš ï¸  å†…å®¹æ‰©å†™å¤±è´¥: {str(e)}")
        return content


def process_research_data(research_data: str,
                          llm_client: LLMClient,
                          summary_length: int = 3000,
                          key_points_count: int = 8) -> Dict[str, Any]:
    """
    å¤„ç†ç ”ç©¶æ•°æ®ï¼Œç”Ÿæˆæ‘˜è¦å’Œå…³é”®è¦ç‚¹
    
    Args:
        research_data: åŸå§‹ç ”ç©¶æ•°æ®
        llm_client: LLMå®¢æˆ·ç«¯
        summary_length: æ‘˜è¦é•¿åº¦
        key_points_count: å…³é”®è¦ç‚¹æ•°é‡
        
    Returns:
        Dict[str, Any]: åŒ…å«æ‘˜è¦å’Œå…³é”®è¦ç‚¹çš„å­—å…¸
    """
    print(f"ğŸ“Š å¤„ç†ç ”ç©¶æ•°æ®: {len(research_data)} å­—ç¬¦")

    # ç”Ÿæˆæ‘˜è¦
    summary = summarize_content(research_data, llm_client, summary_length)

    # æå–å…³é”®è¦ç‚¹
    key_points = extract_key_points(research_data, llm_client,
                                    key_points_count)

    print(f"âœ… æ•°æ®å¤„ç†å®Œæˆ: æ‘˜è¦ {len(summary)} å­—ç¬¦, {len(key_points)} ä¸ªè¦ç‚¹")

    return {
        "summary": summary,
        "key_points": key_points,
        "original_length": len(research_data),
        "processed_length": len(summary)
    }
