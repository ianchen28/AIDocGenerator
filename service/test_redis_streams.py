#!/usr/bin/env python3
"""
Redis Streams æµ‹è¯•è„šæœ¬

æ¼”ç¤ºå‘å¸ƒå™¨å’Œæ¶ˆè´¹è€…çš„å®Œæ•´å·¥ä½œæµç¨‹
"""

import asyncio
import json
import sys
import os
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

import redis.asyncio as redis
from loguru import logger

from doc_agent.core.redis_stream_publisher import RedisStreamPublisher
from doc_agent.core.redis_stream_consumer import (RedisStreamConsumerGroup,
                                                  create_default_consumer_group
                                                  )
from doc_agent.core.config import settings


class RedisStreamsTester:
    """Redis Streams æµ‹è¯•å™¨"""

    def __init__(self):
        self.redis_url = settings.redis_url
        self.redis_client = None
        self.publisher = None
        self.consumer_group = None

    async def setup(self):
        """åˆå§‹åŒ–è¿æ¥"""
        try:
            logger.info(f"Redis URL: {self.redis_url}")
            # è¿æ¥Redis
            self.redis_client = redis.from_url(self.redis_url,
                                               encoding="utf-8",
                                               decode_responses=True)
            await self.redis_client.ping()
            logger.info("âœ… Redisè¿æ¥æˆåŠŸ")

            # åˆå§‹åŒ–å‘å¸ƒå™¨
            self.publisher = RedisStreamPublisher(self.redis_client)

            # åˆå§‹åŒ–æ¶ˆè´¹è€…ç»„
            self.consumer_group = create_default_consumer_group(
                self.redis_url, "test_consumers")

            logger.info("âœ… ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            return True

        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    async def test_publish_events(self, job_id: str):
        """æµ‹è¯•å‘å¸ƒäº‹ä»¶"""
        logger.info(f"ğŸš€ å¼€å§‹æµ‹è¯•å‘å¸ƒäº‹ä»¶: {job_id}")

        try:
            # 1. å‘å¸ƒä»»åŠ¡å¼€å§‹äº‹ä»¶
            await self.publisher.publish_task_started(job_id,
                                                      "outline_generation",
                                                      query="æµ‹è¯•æŸ¥è¯¢")
            logger.info("ğŸ“¤ å‘å¸ƒä»»åŠ¡å¼€å§‹äº‹ä»¶")

            # 2. å‘å¸ƒä»»åŠ¡è¿›åº¦äº‹ä»¶
            await self.publisher.publish_task_progress(job_id,
                                                       "outline_generation",
                                                       "æ­£åœ¨ç”Ÿæˆå¤§çº²...",
                                                       progress_percent=30)
            logger.info("ğŸ“¤ å‘å¸ƒä»»åŠ¡è¿›åº¦äº‹ä»¶")

            # 3. å‘å¸ƒå¤§çº²ç”Ÿæˆå®Œæˆäº‹ä»¶
            outline_data = {
                "title":
                "æµ‹è¯•æ–‡æ¡£å¤§çº²",
                "chapters": [{
                    "title": "ç¬¬ä¸€ç« ",
                    "content": "å†…å®¹1"
                }, {
                    "title": "ç¬¬äºŒç« ",
                    "content": "å†…å®¹2"
                }]
            }
            await self.publisher.publish_outline_generated(
                job_id, outline_data)
            logger.info("ğŸ“¤ å‘å¸ƒå¤§çº²ç”Ÿæˆå®Œæˆäº‹ä»¶")

            # 4. å‘å¸ƒä»»åŠ¡å®Œæˆäº‹ä»¶
            await self.publisher.publish_task_completed(
                job_id, "outline_generation", result={"outline": outline_data})
            logger.info("ğŸ“¤ å‘å¸ƒä»»åŠ¡å®Œæˆäº‹ä»¶")

        except Exception as e:
            logger.error(f"âŒ å‘å¸ƒäº‹ä»¶å¤±è´¥: {e}")

    async def test_consumer_handlers(self, job_id: str):
        """æµ‹è¯•è‡ªå®šä¹‰æ¶ˆè´¹è€…å¤„ç†å™¨"""

        async def custom_task_started_handler(job_id: str, event_data: dict):
            """è‡ªå®šä¹‰ä»»åŠ¡å¼€å§‹å¤„ç†å™¨"""
            logger.info(f"ğŸ¯ è‡ªå®šä¹‰å¤„ç†å™¨ - ä»»åŠ¡å¼€å§‹: {job_id}")
            logger.info(f"   ä»»åŠ¡ç±»å‹: {event_data.get('taskType', 'unknown')}")
            logger.info(f"   æ—¶é—´æˆ³: {event_data.get('timestamp', 'unknown')}")

        async def custom_outline_generated_handler(job_id: str,
                                                   event_data: dict):
            """è‡ªå®šä¹‰å¤§çº²ç”Ÿæˆå¤„ç†å™¨"""
            logger.info(f"ğŸ¯ è‡ªå®šä¹‰å¤„ç†å™¨ - å¤§çº²ç”Ÿæˆ: {job_id}")
            outline = event_data.get('outline', {})
            logger.info(f"   æ–‡æ¡£æ ‡é¢˜: {outline.get('title', 'Unknown')}")
            logger.info(f"   ç« èŠ‚æ•°é‡: {len(outline.get('chapters', []))}")

        # æ³¨å†Œè‡ªå®šä¹‰å¤„ç†å™¨
        self.consumer_group.register_handler("task_started",
                                             custom_task_started_handler)
        self.consumer_group.register_handler("outline_generated",
                                             custom_outline_generated_handler)

        logger.info("ğŸ“ æ³¨å†Œè‡ªå®šä¹‰äº‹ä»¶å¤„ç†å™¨")

    async def run_test(self):
        """è¿è¡Œå®Œæ•´æµ‹è¯•"""
        logger.info("ğŸ§ª å¼€å§‹Redis Streamsæµ‹è¯•")

        # åˆå§‹åŒ–
        if not await self.setup():
            return

        # ç”Ÿæˆæµ‹è¯•ä»»åŠ¡ID
        job_id = f"test_job_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        stream_name = f"job_events:{job_id}"

        try:
            # æ³¨å†Œè‡ªå®šä¹‰å¤„ç†å™¨
            await self.test_consumer_handlers(job_id)

            # å¯åŠ¨æ¶ˆè´¹è€…ç»„
            await self.consumer_group.start(stream_name)
            logger.info("ğŸ‘¥ æ¶ˆè´¹è€…ç»„å·²å¯åŠ¨")

            # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿æ¶ˆè´¹è€…å‡†å¤‡å°±ç»ª
            await asyncio.sleep(2)

            # å‘å¸ƒæµ‹è¯•äº‹ä»¶
            await self.test_publish_events(job_id)

            # ç­‰å¾…äº‹ä»¶å¤„ç†
            logger.info("â³ ç­‰å¾…äº‹ä»¶å¤„ç†...")
            await asyncio.sleep(5)

            # è·å–Streamä¿¡æ¯
            stream_info = await self.publisher.get_stream_info(job_id)
            stream_length = await self.publisher.get_stream_length(job_id)

            logger.info(f"ğŸ“Š Streamä¿¡æ¯:")
            logger.info(f"   é•¿åº¦: {stream_length}")
            if stream_info:
                logger.info(
                    f"   ç¬¬ä¸€ä¸ªID: {stream_info.get('first-entry', ['N/A'])[0]}")
                logger.info(
                    f"   æœ€åä¸€ä¸ªID: {stream_info.get('last-entry', ['N/A'])[0]}")

            # åœæ­¢æ¶ˆè´¹è€…ç»„
            await self.consumer_group.stop()
            logger.info("ğŸ›‘ æ¶ˆè´¹è€…ç»„å·²åœæ­¢")

        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")

        finally:
            # æ¸…ç†è¿æ¥
            if self.redis_client:
                await self.redis_client.close()
            logger.info("ğŸ§¹ æ¸…ç†å®Œæˆ")


async def main():
    """ä¸»å‡½æ•°"""
    tester = RedisStreamsTester()
    await tester.run_test()


if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logger.remove()
    logger.add(
        sys.stderr,
        format=
        "<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
        level="INFO")

    # è¿è¡Œæµ‹è¯•
    asyncio.run(main())
