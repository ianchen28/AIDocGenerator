#!/usr/bin/env python3
"""
æµ‹è¯•æ‰€æœ‰LLMå®¢æˆ·ç«¯çš„å®ç°
"""

from test_base import TestBase, setup_paths

# è®¾ç½®æµ‹è¯•ç¯å¢ƒ
setup_paths()

from src.doc_agent.llm_clients import get_llm_client, get_reranker_client, get_embedding_client
from core.config import settings


class LLMClientsTest(TestBase):
    """LLMå®¢æˆ·ç«¯æµ‹è¯•ç±»"""

    def test_config_loading(self):
        """æµ‹è¯•é…ç½®åŠ è½½"""
        print("=== æµ‹è¯•é…ç½®åŠ è½½ ===")

        try:
            models = settings.supported_models
            print(f"âœ… æ”¯æŒçš„æ¨¡å‹æ•°é‡: {len(models)}")

            for model_key, model_config in list(models.items())[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(
                    f"  - {model_key}: {model_config.name} ({model_config.type})"
                )
                print(f"    URL: {model_config.url}")
                print(f"    Model ID: {model_config.model_id}")

            return True

        except Exception as e:
            print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {str(e)}")
            return False

    def test_client_creation(self):
        """æµ‹è¯•å®¢æˆ·ç«¯åˆ›å»º"""
        print("=== æµ‹è¯•å®¢æˆ·ç«¯åˆ›å»º ===")

        try:
            # æµ‹è¯•ä¸åŒæ¨¡å‹çš„å®¢æˆ·ç«¯åˆ›å»º
            test_models = [
                "qwen_2_5_235b_a22b",  # ä¼ä¸šæ¨¡å‹
                "gemini_1_5_pro",  # Geminiæ¨¡å‹
                "deepseek_v3",  # DeepSeekæ¨¡å‹
            ]

            success_count = 0
            for model_key in test_models:
                try:
                    client = get_llm_client(model_key=model_key)
                    print(f"  âœ… {model_key}: å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
                    print(f"     ç±»å‹: {type(client).__name__}")

                    # æ£€æŸ¥URLé…ç½®
                    if hasattr(client, 'base_url'):
                        print(f"     Base URL: {client.base_url}")
                    elif hasattr(client, 'api_key'):
                        print(f"     API Key: {client.api_key}")

                    success_count += 1

                except Exception as e:
                    print(f"  âŒ {model_key}: {str(e)}")

            return success_count > 0

        except Exception as e:
            print(f"âŒ å®¢æˆ·ç«¯åˆ›å»ºæµ‹è¯•å¤±è´¥: {str(e)}")
            return False

    def test_specialized_clients(self):
        """æµ‹è¯•ä¸“é—¨çš„å®¢æˆ·ç«¯"""
        print("=== æµ‹è¯•ä¸“é—¨å®¢æˆ·ç«¯ ===")

        try:
            success_count = 0

            # æµ‹è¯•Rerankerå®¢æˆ·ç«¯
            try:
                reranker_client = get_reranker_client()
                print(f"  âœ… Reranker: å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
                print(f"     ç±»å‹: {type(reranker_client).__name__}")
                print(f"     Base URL: {reranker_client.base_url}")
                success_count += 1
            except Exception as e:
                print(f"  âŒ Reranker: {str(e)}")

            # æµ‹è¯•Embeddingå®¢æˆ·ç«¯
            try:
                embedding_client = get_embedding_client()
                print(f"  âœ… Embedding: å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
                print(f"     ç±»å‹: {type(embedding_client).__name__}")
                print(f"     Base URL: {embedding_client.base_url}")
                success_count += 1
            except Exception as e:
                print(f"  âŒ Embedding: {str(e)}")

            return success_count > 0

        except Exception as e:
            print(f"âŒ ä¸“é—¨å®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {str(e)}")
            return False

    def test_client_invoke(self):
        """å®é™…è°ƒç”¨å„ç±» client çš„ invoke æ–¹æ³•å¹¶æ£€æŸ¥è¿”å›å€¼æœ‰æ•ˆæ€§"""
        print("=== æµ‹è¯•å®¢æˆ·ç«¯å®é™…è°ƒç”¨ ===")
        success_count = 0
        total = 0
        # 1. LLM Client
        try:
            client = get_llm_client(model_key="qwen_2_5_235b_a22b")
            response = client.invoke("ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚",
                                     temperature=0.7,
                                     max_tokens=100)
            print(f"  âœ… LLM invoke è¿”å›: {str(response)[:60]}...")
            if isinstance(response, str) and len(response.strip()) > 0:
                success_count += 1
            else:
                print("  âŒ LLM invoke è¿”å›å†…å®¹å¼‚å¸¸")
            total += 1
        except Exception as e:
            print(f"  âŒ LLM invoke å¼‚å¸¸: {e}")
            total += 1
        # 2. Gemini Client
        try:
            gemini_client = get_llm_client(model_key="gemini_1_5_pro")
            response = gemini_client.invoke("ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚",
                                            temperature=0.7,
                                            max_tokens=100)
            print(f"  âœ… Gemini invoke è¿”å›: {str(response)[:60]}...")
            if isinstance(response, str) and len(response.strip()) > 0:
                success_count += 1
            else:
                print("  âŒ Gemini invoke è¿”å›å†…å®¹å¼‚å¸¸")
            total += 1
        except Exception as e:
            print(f"  âŒ Gemini invoke å¼‚å¸¸: {e}")
            total += 1
        # 3. Reranker
        try:
            reranker = get_reranker_client()
            test_docs = [
                "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯", "æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«æ–¹é¢å–å¾—äº†çªç ´", "è‡ªç„¶è¯­è¨€å¤„ç†è®©æœºå™¨èƒ½å¤Ÿç†è§£äººç±»è¯­è¨€",
                "å¼ºåŒ–å­¦ä¹ é€šè¿‡å¥–åŠ±æœºåˆ¶è®­ç»ƒæ™ºèƒ½ä½“"
            ]
            result = reranker.invoke("äººå·¥æ™ºèƒ½",
                                     documents=test_docs,
                                     size=len(test_docs))
            print("  âœ… Reranker invoke å®Œæ•´è¿”å›:", result)
            if result and isinstance(
                    result, dict) and "sorted_doc_list" in result and len(
                        result["sorted_doc_list"]) > 0:
                sorted_docs = result["sorted_doc_list"]
                print("     æ’åºç»“æœï¼š")
                for i, doc in enumerate(sorted_docs):
                    print(
                        f"     {i+1}. åˆ†æ•°: {doc.get('rerank_score', 'N/A')}, å†…å®¹: {doc.get('text', '')[:30]}"
                    )
                success_count += 1
            else:
                print("  âŒ Reranker invoke è¿”å›å†…å®¹å¼‚å¸¸")
            total += 1
        except Exception as e:
            print(f"  âŒ Reranker invoke å¼‚å¸¸: {e}")
            total += 1
        # 4. Embedding
        try:
            embedding = get_embedding_client()
            vector = embedding.invoke("æ–‡æœ¬å†…å®¹")
            print(f"  âœ… Embedding invoke è¿”å›: {str(vector)[:60]}...")
            if vector is not None and hasattr(vector,
                                              "__len__") and len(vector) > 0:
                success_count += 1
            else:
                print("  âŒ Embedding invoke è¿”å›å†…å®¹å¼‚å¸¸")
            total += 1
        except Exception as e:
            print(f"  âŒ Embedding invoke å¼‚å¸¸: {e}")
            total += 1
        print(f"\nå®é™…è°ƒç”¨é€šè¿‡: {success_count}/{total}")
        return success_count == total

    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹LLMå®¢æˆ·ç«¯æµ‹è¯•...")

        test_results = []

        # è¿è¡Œå„é¡¹æµ‹è¯•
        test_results.append(("é…ç½®åŠ è½½", self.test_config_loading()))
        test_results.append(("å®¢æˆ·ç«¯åˆ›å»º", self.test_client_creation()))
        test_results.append(("ä¸“é—¨å®¢æˆ·ç«¯", self.test_specialized_clients()))
        test_results.append(("å®é™…è°ƒç”¨", self.test_client_invoke()))

        # æ˜¾ç¤ºæµ‹è¯•ç»“æœ
        print("\n" + "=" * 50)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
        print("=" * 50)

        passed = 0
        for test_name, result in test_results:
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"{test_name}: {status}")
            if result:
                passed += 1

        print(f"\næ€»è®¡: {passed}/{len(test_results)} é¡¹æµ‹è¯•é€šè¿‡")

        if passed == len(test_results):
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        else:
            print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥")

        # æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹
        print("\nğŸ¯ ä½¿ç”¨ç¤ºä¾‹:")
        print("""
# ä½¿ç”¨ç‰¹å®šæ¨¡å‹ï¼ˆURLä»é…ç½®è‡ªåŠ¨è·å–ï¼‰
client = get_llm_client(model_key="qwen_2_5_235b_a22b")
response = client.invoke("ä½ å¥½", temperature=0.7, max_tokens=1000)

# ä½¿ç”¨Geminiï¼ˆURLä»é…ç½®è·å–ï¼‰
gemini_client = get_llm_client(model_key="gemini_1_5_pro")
response = gemini_client.invoke("ä½ å¥½", temperature=0.7, max_tokens=1000)

# ä½¿ç”¨Reranker
reranker = get_reranker_client()
result = reranker.invoke("æŸ¥è¯¢", documents=["æ–‡æ¡£1", "æ–‡æ¡£2"])

# ä½¿ç”¨Embedding
embedding = get_embedding_client()
vector = embedding.invoke("æ–‡æœ¬å†…å®¹")
        """)


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    tester = LLMClientsTest()
    tester.run_all_tests()


if __name__ == "__main__":
    main()
