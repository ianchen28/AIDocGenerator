#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLMé…ç½®æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯ä¸åŒæ¨¡å‹æœåŠ¡çš„é…ç½®å’Œè¿æ¥
"""

import sys
import os
from pathlib import Path

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['PYTHONPATH'] = '/Users/chenyuyang/git/AIDocGenerator/service'

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_file = Path(__file__)
service_dir = current_file.parent
if str(service_dir) not in sys.path:
    sys.path.insert(0, str(service_dir))

from core.env_loader import setup_environment
from core.config import settings
from src.doc_agent.llm_clients import get_llm_client


def test_model_configs():
    """æµ‹è¯•æ‰€æœ‰æ¨¡å‹é…ç½®"""
    print("ğŸ§ª æµ‹è¯•æ¨¡å‹é…ç½®")
    print("=" * 80)

    # 1. æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨æ¨¡å‹
    print("ğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨:")
    for model_key, config in settings.supported_models.items():
        print(f"  - {model_key}: {config.name} ({config.type})")
    print()

    # 2. æµ‹è¯•ç‰¹å®šæ¨¡å‹
    test_models = [
        "moonshot_k2_0711_preview",  # Moonshot
        "gemini_1_5_pro",  # Gemini
        "deepseek_v3",  # DeepSeek
        "qwen_2_5_235b_a22b",  # ä¼ä¸šå†…ç½‘æ¨¡å‹
    ]

    for model_key in test_models:
        print(f"ğŸ” æµ‹è¯•æ¨¡å‹: {model_key}")
        try:
            # è·å–æ¨¡å‹é…ç½®
            model_config = settings.get_model_config(model_key)
            if not model_config:
                print(f"  âŒ æ¨¡å‹é…ç½®æœªæ‰¾åˆ°: {model_key}")
                continue

            print(f"  ğŸ“ æ¨¡å‹åç§°: {model_config.name}")
            print(f"  ğŸ”— APIåœ°å€: {model_config.url}")
            print(f"  ğŸ§  æ¨ç†æ¨¡å¼: {model_config.reasoning}")

            # åˆ›å»ºå®¢æˆ·ç«¯
            client = get_llm_client(model_key)
            print(f"  âœ… å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ: {type(client).__name__}")

            # ç®€å•æµ‹è¯•è°ƒç”¨
            test_prompt = "è¯·ç®€å•å›ç­”ï¼š1+1ç­‰äºå‡ ï¼Ÿ"
            print(f"  ğŸ§ª æµ‹è¯•è°ƒç”¨: {test_prompt}")

            response = client.invoke(test_prompt, temperature=0, max_tokens=50)
            print(f"  ğŸ“¤ å“åº”: {response[:100]}...")
            print(f"  âœ… æ¨¡å‹ {model_key} æµ‹è¯•æˆåŠŸ")

        except Exception as e:
            print(f"  âŒ æ¨¡å‹ {model_key} æµ‹è¯•å¤±è´¥: {str(e)}")

        print("-" * 80)


def test_container_config():
    """æµ‹è¯•å®¹å™¨é…ç½®"""
    print("\nğŸ”§ æµ‹è¯•å®¹å™¨é…ç½®")
    print("=" * 80)

    try:
        from core.container import container

        print("âœ… å®¹å™¨åˆ›å»ºæˆåŠŸ")
        print(f"ğŸ“‹ LLMå®¢æˆ·ç«¯ç±»å‹: {type(container.llm_client).__name__}")
        print(f"ğŸ” æœç´¢å·¥å…·ç±»å‹: {type(container.search_tool).__name__}")
        print(f"ğŸ“Š å›¾å¯¹è±¡ç±»å‹: {type(container.graph).__name__}")

        # æµ‹è¯•å›¾ç¼–è¯‘
        print("\nğŸ§ª æµ‹è¯•å›¾ç¼–è¯‘...")
        initial_input = {
            "messages": [],
            "topic": "æµ‹è¯•ä¸»é¢˜",
            "research_plan": "",
            "search_queries": [],
            "gathered_data": "",
            "final_document": ""
        }

        print("âœ… å›¾ç¼–è¯‘æˆåŠŸï¼Œå¯ä»¥æ‰§è¡Œ")

    except Exception as e:
        print(f"âŒ å®¹å™¨é…ç½®æµ‹è¯•å¤±è´¥: {str(e)}")


def test_agent_components():
    """æµ‹è¯•Agentç»„ä»¶é…ç½®"""
    print("\nğŸ¤– æµ‹è¯•Agentç»„ä»¶é…ç½®")
    print("=" * 80)

    components = [
        "task_planner", "retriever", "executor", "composer", "validator"
    ]

    for component in components:
        try:
            config = settings.get_agent_component_config(component)
            if config:
                print(f"âœ… {component}: {config.name} ({config.provider})")
                print(f"   - æ¸©åº¦: {config.temperature}")
                print(f"   - æœ€å¤§token: {config.max_tokens}")
                print(f"   - è¶…æ—¶: {config.timeout}ç§’")
            else:
                print(f"âŒ {component}: é…ç½®æœªæ‰¾åˆ°")
        except Exception as e:
            print(f"âŒ {component}: é…ç½®é”™è¯¯ - {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ LLMé…ç½®æµ‹è¯•å¼€å§‹")
    print("=" * 80)

    # è®¾ç½®ç¯å¢ƒ
    setup_environment()

    # è¿è¡Œæµ‹è¯•
    test_model_configs()
    test_container_config()
    test_agent_components()

    print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    main()
