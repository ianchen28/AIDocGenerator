#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿç«¯åˆ°ç«¯å›¾å·¥ä½œæµæµ‹è¯•è„šæœ¬
ä¼˜åŒ–ç‰ˆæœ¬ï¼Œå‡å°‘è€—æ—¶ï¼Œå¿«é€ŸéªŒè¯åŠŸèƒ½
"""

import sys
import os
import json
from datetime import datetime
from pathlib import Path

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['PYTHONPATH'] = '/Users/chenyuyang/git/AIDocGenerator/service'

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_file = Path(__file__)
service_dir = current_file.parent / "service"
src_dir = service_dir / "src"
for p in [str(service_dir), str(src_dir)]:
    if p not in sys.path:
        sys.path.insert(0, p)

# è®¾ç½®ç¯å¢ƒå˜é‡
from core.env_loader import setup_environment

setup_environment()

from core.container import Container


def setup_output_dir():
    """è®¾ç½®è¾“å‡ºç›®å½•"""
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)

    # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„å­ç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    session_dir = output_dir / f"fast_test_{timestamp}"
    session_dir.mkdir(exist_ok=True)

    return session_dir


def save_document(session_dir: Path, document: str, topic: str):
    """ä¿å­˜ç”Ÿæˆçš„æ–‡æ¡£"""
    # æ¸…ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦
    safe_topic = "".join(c for c in topic
                         if c.isalnum() or c in (' ', '-', '_')).rstrip()
    safe_topic = safe_topic.replace(' ', '_')[:30]  # é™åˆ¶é•¿åº¦

    doc_file = session_dir / f"{safe_topic}.md"
    with open(doc_file, 'w', encoding='utf-8') as f:
        f.write(document)
    print(f"ğŸ“„ æ–‡æ¡£å·²ä¿å­˜åˆ°: {doc_file}")


async def test_graph_fast():
    """å¿«é€Ÿæµ‹è¯•å›¾æµç¨‹"""
    print("ğŸš€ å¼€å§‹å¿«é€Ÿç«¯åˆ°ç«¯æµ‹è¯•...")

    # è®¾ç½®è¾“å‡ºç›®å½•
    session_dir = setup_output_dir()
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {session_dir}")

    def log(message: str):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] {message}")

    # è·å–å®¹å™¨å’Œé…ç½®
    container = Container()
    from core.config import settings

    # è·å–å¿«é€Ÿæ¨¡å¼é…ç½®
    doc_config = settings.get_document_config(fast_mode=True)
    log(f"âš™ï¸  å¿«é€Ÿæ¨¡å¼é…ç½®: æ€»å­—æ•°={doc_config['total_target_words']}, ç« èŠ‚å­—æ•°={doc_config['chapter_target_words']}"
        )
    log(f"ğŸ” ESæ£€ç´¢é…ç½®: å‘é‡å¬å›={doc_config['vector_recall_size']}, æ··åˆå¬å›={doc_config['hybrid_recall_size']}, é‡æ’={doc_config['rerank_size']}"
        )

    try:
        # åˆ›å»ºç®€åŒ–çš„åˆå§‹çŠ¶æ€ - ä½¿ç”¨ç”µåŠ›ç³»ç»Ÿä¸»é¢˜ï¼Œå‡å°‘æœç´¢æŸ¥è¯¢æ•°é‡
        initial_state = {
            "topic": "æ™ºèƒ½ç”µç½‘æŠ€æœ¯åœ¨ç”µåŠ›ç³»ç»Ÿä¸­çš„åº”ç”¨",
            "search_queries": ["æ™ºèƒ½ç”µç½‘ ç”µåŠ›ç³»ç»Ÿ æŠ€æœ¯åº”ç”¨", "AI ç”µåŠ›è°ƒåº¦ ä¼˜åŒ–ç®—æ³•"]
        }

        topic = initial_state["topic"]
        log(f"ğŸ“‹ å¿«é€Ÿæµ‹è¯•ä¸»é¢˜: {topic}")

        # æµå¼æ‰§è¡Œå›¾
        async for event in container.main_graph.astream(initial_state):
            node_name = list(event.keys())[0]
            node_output = event[node_name]

            log(f"ğŸ” æ‰§è¡ŒèŠ‚ç‚¹: {node_name}")

            if node_name == "planner":
                search_queries = node_output.get('search_queries', [])
                log(f"ğŸ“ ç”Ÿæˆ {len(search_queries)} ä¸ªæœç´¢æŸ¥è¯¢")

            elif node_name == "researcher":
                gathered_data = node_output.get('gathered_data', '')
                log(f"ğŸ“š æ”¶é›†æ•°æ®: {len(gathered_data)} å­—ç¬¦")

            elif node_name == "writer":
                final_document = node_output.get('final_document', '')
                log(f"ğŸ“„ ç”Ÿæˆæ–‡æ¡£: {len(final_document)} å­—ç¬¦")
                log("ğŸ›‘ writer èŠ‚ç‚¹å®Œæˆï¼Œåœæ­¢æ‰§è¡Œ")
                break

            elif node_name == "supervisor_router":
                decision = node_output.get('decision', '')
                log(f"ğŸ¯ è·¯ç”±å†³ç­–: {decision}")
                log("ğŸ›‘ supervisor_router èŠ‚ç‚¹å®Œæˆï¼Œåœæ­¢æ‰§è¡Œ")
                break

            elif node_name == "finalize_document":
                final_document = node_output.get('final_document', '')
                log(f"ğŸ“„ æœ€ç»ˆæ–‡æ¡£: {len(final_document)} å­—ç¬¦")
                log("ğŸ›‘ finalize_document èŠ‚ç‚¹å®Œæˆï¼Œæµç¨‹ç»“æŸ")
                break

        # ä¿å­˜æœ€ç»ˆæ–‡æ¡£
        if final_document and topic:
            save_document(session_dir, final_document, topic)

        log("\nâœ… å¿«é€Ÿæµ‹è¯•å®Œæˆ!")
        return True

    except Exception as e:
        log(f"\nâŒ å¿«é€Ÿæµ‹è¯•å¤±è´¥: {str(e)}")
        return False

    finally:
        # æ¸…ç†èµ„æº
        log("ğŸ§¹ æ¸…ç†èµ„æº...")
        try:
            await container.cleanup()
            log("âœ… èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            log(f"âš ï¸  èµ„æºæ¸…ç†æ—¶å‡ºé”™: {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª å¿«é€Ÿç«¯åˆ°ç«¯å›¾å·¥ä½œæµæµ‹è¯•")
    print("=" * 60)
    print("âš¡ ä¼˜åŒ–é…ç½®:")
    print("  - å‡å°‘æœç´¢æŸ¥è¯¢æ•°é‡")
    print("  - ç®€åŒ–æµ‹è¯•ä¸»é¢˜")
    print("  - ç²¾ç®€æ—¥å¿—è¾“å‡º")
    print("=" * 60)

    import asyncio
    success = asyncio.run(test_graph_fast())

    if success:
        print("\nâœ… å¿«é€Ÿæµ‹è¯•å®Œæˆ!")
    else:
        print("\nâŒ å¿«é€Ÿæµ‹è¯•å¤±è´¥!")


if __name__ == "__main__":
    main()
